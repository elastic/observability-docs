---
id: serverlessObservabilityLogMonitoring
slug: /serverless/observability/log-monitoring
title: Log monitoring
description: Use Elastic to deploy and manage logs at a petabyte scale, and get insights from your logs in minutes.
tags: [ 'serverless', 'observability', 'overview' ]
---

<p><DocBadge template="technical preview" /></p>

Elastic Observability allows you to deploy and manage logs at a petabyte scale, giving you insights into your logs in minutes. You can also search across your logs in one place, troubleshoot in real time, and detect patterns and outliers with categorization and anomaly detection. For more information, refer to the following links:

- <DocLink id="serverlessObservabilityGetStartedWithLogs">Get started with system logs</DocLink>: Onboard system log data from a machine or server.
- <DocLink id="serverlessObservabilityStreamLogFiles">Stream any log file</DocLink>: Send log files to your Observability project using a standalone ((agent)).
- <DocLink id="serverlessObservabilityParseLogData">Parse and route logs</DocLink>: Parse your log data and extract structured fields that you can use to analyze your data.
- <DocLink id="serverlessObservabilityFilterAndAggregateLogs" section="filter-logs">Filter and aggregate logs</DocLink>: Filter and aggregate your log data to find specific information, gain insight, and monitor your systems more efficiently.
- <DocLink id="serverlessObservabilityDiscoverAndExploreLogs">Explore logs</DocLink>: Find information on visualizing and analyzing logs.
- <DocLink id="serverlessObservabilityRunLogPatternAnalysis">Run pattern analysis on log data</DocLink>: Find patterns in unstructured log messages and make it easier to examine your data.
- <DocLink id="serverlessObservabilityTroubleshootLogs">Troubleshoot logs</DocLink>: Find solutions for errors you might encounter while onboarding your logs.

## Send logs data to your project

You can send logs data to your project in different ways depending on your needs:

- ((agent))
- ((filebeat))

When choosing between ((agent)) and ((filebeat)), consider the different features and functionalities between the two options.
See [((beats)) and ((agent)) capabilities](((fleet-guide))/beats-agent-comparison.html) for more information on which option best fits your situation.

### ((agent))

((agent)) uses [integrations](https://www.elastic.co/integrations/data-integrations) to ingest logs from Kubernetes, MySQL, and many more data sources.
You have the following options when installing and managing an ((agent)):

#### ((fleet))-managed ((agent))

Install an ((agent)) and use ((fleet)) to define, configure, and manage your agents in a central location.

See [install ((fleet))-managed ((agent))](((fleet-guide))/install-fleet-managed-elastic-agent.html).

#### Standalone ((agent))

Install an ((agent)) and manually configure it locally on the system where itâ€™s installed.
You are responsible for managing and upgrading the agents.

See [install standalone ((agent))](((fleet-guide))/install-standalone-elastic-agent.html).

#### ((agent)) in a containerized environment

Run an ((agent)) inside of a container &mdash; either with ((fleet-server)) or standalone.

See [install ((agent)) in containers](((fleet-guide))/install-elastic-agents-in-containers.html).

### ((filebeat))

((filebeat)) is a lightweight shipper for forwarding and centralizing log data.
Installed as a service on your servers, ((filebeat)) monitors the log files or locations that you specify, collects log events, and forwards them to your Observability project for indexing.

- [((filebeat)) overview](((filebeat-ref))/filebeat-overview.html): General information on ((filebeat)) and how it works.
- [((filebeat)) quick start](((filebeat-ref))/filebeat-installation-configuration.html): Basic installation instructions to get you started.
- [Set up and run ((filebeat))](((filebeat-ref))/setting-up-and-running.html): Information on how to install, set up, and run ((filebeat)).

## Configure logs

The following resources provide information on configuring your logs:

- [Data streams](((ref))/data-streams.html): Efficiently store append-only time series data in multiple backing indices partitioned by time and size.
- [Data views](((kibana-ref))/data-views.html): Query log entries from the data streams of specific datasets or namespaces.
- [Index lifecycle management](((ref))/example-using-index-lifecycle-policy.html): Configure the built-in logs policy based on your application's performance, resilience, and retention requirements.
- [Ingest pipeline](((ref))/ingest.html): Parse and transform log entries into a suitable format before indexing.
- [Mapping](((ref))/mapping.html): Define how data is stored and indexed.

## View and monitor logs

Use **Logs Explorer** to search, filter, and tail all your logs ingested into your project in one place.

The following resources provide information on viewing and monitoring your logs:

- <DocLink id="serverlessObservabilityDiscoverAndExploreLogs">Discover and explore</DocLink>: Discover and explore all of the log events flowing in from your servers, virtual machines, and containers in a centralized view.
- <DocLink id="serverlessObservabilityAiopsDetectAnomalies">Detect log anomalies</DocLink>: Use ((ml)) to detect log anomalies automatically.

## Application logs

Application logs provide valuable insight into events that have occurred within your services and applications.
See <DocLink id="serverlessObservabilityCorrelateApplicationLogs">Application logs</DocLink>.

{/* ## Create a logs threshold alert

You can create a rule to send an alert when the log aggregation exceeds a threshold.
See <DocLink id="serverlessObservabilityCreateLogThresholdRule">Create a logs threshold rule</DocLink>. */}
