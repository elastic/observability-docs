[[observability-log-monitoring]]
= Log monitoring

++++
<titleabbrev>Logs</titleabbrev>
++++

// :description: Use Elastic to deploy and manage logs at a petabyte scale, and get insights from your logs in minutes.
// :keywords: serverless, observability, overview

Elastic Observability allows you to deploy and manage logs at a petabyte scale, giving you insights into your logs in minutes. You can also search across your logs in one place, troubleshoot in real time, and detect patterns and outliers with categorization and anomaly detection. For more information, refer to the following links:

* <<observability-get-started-with-logs,Get started with system logs>>: Onboard system log data from a machine or server.
* <<observability-stream-log-files,Stream any log file>>: Send log files to your Observability project using a standalone {agent}.
* <<observability-parse-log-data,Parse and route logs>>: Parse your log data and extract structured fields that you can use to analyze your data.
* <<logs-filter,Filter and aggregate logs>>: Filter and aggregate your log data to find specific information, gain insight, and monitor your systems more efficiently.
* <<observability-discover-and-explore-logs,Explore logs>>: Find information on visualizing and analyzing logs.
* <<observability-run-log-pattern-analysis,Run pattern analysis on log data>>: Find patterns in unstructured log messages and make it easier to examine your data.
* <<observability-troubleshoot-logs,Troubleshoot logs>>: Find solutions for errors you might encounter while onboarding your logs.

[discrete]
[[observability-log-monitoring-send-logs-data-to-your-project]]
== Send logs data to your project

You can send logs data to your project in different ways depending on your needs:

* {agent}
* {filebeat}

When choosing between {agent} and {filebeat}, consider the different features and functionalities between the two options.
See {fleet-guide}/beats-agent-comparison.html[{beats} and {agent} capabilities] for more information on which option best fits your situation.

[discrete]
[[observability-log-monitoring-agent]]
=== {agent}

{agent} uses https://www.elastic.co/integrations/data-integrations[integrations] to ingest logs from Kubernetes, MySQL, and many more data sources.
You have the following options when installing and managing an {agent}:

[discrete]
[[observability-log-monitoring-fleet-managed-agent]]
==== {fleet}-managed {agent}

Install an {agent} and use {fleet} to define, configure, and manage your agents in a central location.

See {fleet-guide}/install-fleet-managed-elastic-agent.html[install {fleet}-managed {agent}].

[discrete]
[[observability-log-monitoring-standalone-agent]]
==== Standalone {agent}

Install an {agent} and manually configure it locally on the system where it’s installed.
You are responsible for managing and upgrading the agents.

See {fleet-guide}/install-standalone-elastic-agent.html[install standalone {agent}].

[discrete]
[[observability-log-monitoring-agent-in-a-containerized-environment]]
==== {agent} in a containerized environment

Run an {agent} inside of a container — either with {fleet-server} or standalone.

See {fleet-guide}/install-elastic-agents-in-containers.html[install {agent} in containers].

[discrete]
[[observability-log-monitoring-filebeat]]
=== {filebeat}

{filebeat} is a lightweight shipper for forwarding and centralizing log data.
Installed as a service on your servers, {filebeat} monitors the log files or locations that you specify, collects log events, and forwards them to your Observability project for indexing.

* {filebeat-ref}/filebeat-overview.html[{filebeat} overview]: General information on {filebeat} and how it works.
* {filebeat-ref}/filebeat-installation-configuration.html[{filebeat} quick start]: Basic installation instructions to get you started.
* {filebeat-ref}/setting-up-and-running.html[Set up and run {filebeat}]: Information on how to install, set up, and run {filebeat}.

[discrete]
[[observability-log-monitoring-configure-logs]]
== Configure logs

The following resources provide information on configuring your logs:

* {ref}/data-streams.html[Data streams]: Efficiently store append-only time series data in multiple backing indices partitioned by time and size.
* {kibana-ref}/data-views.html[Data views]: Query log entries from the data streams of specific datasets or namespaces.
* {ref}/example-using-index-lifecycle-policy.html[Index lifecycle management]: Configure the built-in logs policy based on your application's performance, resilience, and retention requirements.
* {ref}/ingest.html[Ingest pipeline]: Parse and transform log entries into a suitable format before indexing.
* {ref}/mapping.html[Mapping]: Define how data is stored and indexed.

[discrete]
[[observability-log-monitoring-view-and-monitor-logs]]
== View and monitor logs

Use **Logs Explorer** to search, filter, and tail all your logs ingested into your project in one place.

The following resources provide information on viewing and monitoring your logs:

* <<observability-discover-and-explore-logs,Discover and explore>>: Discover and explore all of the log events flowing in from your servers, virtual machines, and containers in a centralized view.
* <<observability-aiops-detect-anomalies,Detect log anomalies>>: Use {ml} to detect log anomalies automatically.

[discrete]
[[observability-log-monitoring-monitor-data-sets]]
== Monitor data sets

The **Data Set Quality** page provides an overview of your data sets and their quality.
Use this information to get an idea of your overall data set quality, and find data sets that contain incorrectly parsed documents.

<<observability-monitor-datasets,Monitor data sets>>

[discrete]
[[observability-log-monitoring-application-logs]]
== Application logs

Application logs provide valuable insight into events that have occurred within your services and applications.
See <<observability-correlate-application-logs,Application logs>>.

////
/* ## Create a logs threshold alert

You can create a rule to send an alert when the log aggregation exceeds a threshold.
See <DocLink id="serverlessObservabilityCreateLogThresholdRule">Create a logs threshold rule</DocLink>. */
////
