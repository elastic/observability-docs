[[observability-apm-service-overview]]
= Service Overview

// :keywords: serverless, observability, reference

Selecting a  <<observability-apm-services,**service**>> brings you to the **Service overview**.
The **Service overview** contains a wide variety of charts and tables that provide
high-level visibility into how a service is performing across your infrastructure:

* Service details like service version, runtime version, framework, and APM agent name and version
* Container and orchestration information
* Cloud provider, machine type, service name, region, and availability zone
* Serverless function names and event trigger type
* Latency, throughput, and errors over time
* Service dependencies

[discrete]
[[observability-apm-service-overview-time-series-and-expected-bounds-comparison]]
== Time series and expected bounds comparison

For insight into the health of your services, you can compare how a service
performs relative to a previous time frame or to the expected bounds from the
corresponding {anomaly-job}. For example, has latency been slowly increasing
over time, did the service experience a sudden spike, is the throughput similar
to what the {ml} job expects — enabling a comparison can provide the answer.

[role="screenshot"]
image::images/services/time-series-expected-bounds-comparison.png[Time series and expected bounds comparison]

Select the **Comparison** box to apply a time-based or expected bounds comparison.
The time-based comparison options are based on the selected time filter range:

|===
| Time filter| Time comparison options

| ≤ 24 hours
| One day or one week

| > 24 hours and ≤ 7 days
| One week

| > 7 days
| An identical amount of time immediately before the selected time range
|===

The expected bounds comparison is powered by <<observability-apm-integrate-with-machine-learning,machine learning>> and requires anomaly detection to be enabled.

[discrete]
[[observability-apm-service-overview-latency]]
== Latency

Response times for the service. You can filter the **Latency** chart to display the average,
95th, or 99th percentile latency times for the service.

[role="screenshot"]
image::images/services/latency.png[Service latency]

[discrete]
[[observability-apm-service-overview-throughput-and-transactions]]
== Throughput and transactions

include::../../../transclusion/kibana/apm/service-overview/throughput-transactions.asciidoc[]

[discrete]
[[observability-apm-service-overview-failed-transaction-rate-and-errors]]
== Failed transaction rate and errors

include::../../../transclusion/kibana/apm/service-overview/ftr.asciidoc[]

The **Errors** table provides a high-level view of each error message when it first and last occurred,
along with the total number of occurrences. This makes it very easy to quickly see which errors affect
your services and take actions to rectify them. To do so, click **View errors**.

[role="screenshot"]
image::images/services/error-rate.png[failed transaction rate and errors]

[discrete]
[[observability-apm-service-overview-span-types-average-duration-and-dependencies]]
== Span types average duration and dependencies

The **Time spent by span type** chart visualizes each span type's average duration and helps you determine
which spans could be slowing down transactions. The "app" label displayed under the
chart indicates that something was happening within the application. This could signal that the APM
agent does not have auto-instrumentation for whatever was happening during that time or that the time was spent in the
application code and not in database or external requests.

include::../../../transclusion/kibana/apm/service-overview/dependencies.asciidoc[]

[discrete]
[[observability-apm-service-overview-cold-start-rate]]
== Cold start rate

The cold start rate chart is specific to serverless services, and displays the
percentage of requests that trigger a cold start of a serverless function.
A cold start occurs when a serverless function has not been used for a certain period of time.
Analyzing the cold start rate can be useful for deciding how much memory to allocate to a function,
or when to remove a large dependency.

The cold start rate chart is currently supported for <<observability-apm-observe-lambda-functions-cold-starts,AWS Lambda>>
functions and Azure functions.

[discrete]
[[observability-apm-service-overview-instances]]
== Instances

The **Instances** table displays a list of all the available service instances within the selected time range.
Depending on how the service runs, the instance could be a host or a container. The table displays latency, throughput,
failed transaction, CPU usage, and memory usage for each instance. By default, instances are sorted by _Throughput_.

[role="screenshot"]
image::images/services/all-instances.png[All instances]

[discrete]
[[observability-apm-service-overview-service-metadata]]
== Service metadata

To view metadata relating to the service agent, and if relevant, the container and cloud provider,
click on each icon located at the top of the page beside the service name.

[role="screenshot"]
image::images/services/metadata-icons.png[Service metadata]

**Service information**

* Service version
* Runtime name and version
* Framework name
* APM agent name and version

**Container information**

* Operating system
* Containerized (yes or no)
* Total number of instances
* Orchestration

**Cloud provider information**

* Cloud provider
* Cloud service name
* Availability zones
* Machine types
* Project ID
* Region

**Serverless information**

* Function name(s)
* Event trigger type

**Alerts**

* Recently fired alerts
