[[observability-create-latency-threshold-alert-rule]]
= Create a latency threshold rule

// :description: Get alerts when the latency of a specific transaction type in a service exceeds a defined threshold.
// :keywords: serverless, observability, how-to, alerting

++++
<titleabbrev>Latency threshold</titleabbrev>
++++

preview:[]

:role: Editor
:goal: create latency threshold rules
include::../partials/roles.asciidoc[]
:role!:

:goal!:

You can create a latency threshold rule to alert you when the latency of a specific transaction type in a service exceeds a defined threshold. Threshold rules can be set at different levels: environment, service, transaction type, and/or transaction name. Add actions to raise alerts via services or third-party integrations e.g. mail, Slack, Jira.

[role="screenshot"]
image::images/alerts-create-rule-apm-latency-threshold.png[Create rule for APM latency threshold alert]

[TIP]
====
These steps show how to use the **Alerts** UI.
You can also create a latency threshold rule directly from any page within **Applications**. Click the **Alerts and rules** button, and select **Create threshold rule** and then **Latency**. When you create a rule this way, the **Name** and **Tags** fields will be prepopulated but you can still change these.
====

To create your latency threshold rule:

. In your {obs-serverless} project, go to **Alerts**.
. Select **Manage Rules** from the **Alerts** page, and select **Create rule**.
. Enter a **Name** for your rule, and any optional **Tags** for more granular reporting (leave blank if unsure).
. Select the **Latency threshold** rule type from the APM use case.
. Select the appropriate **Service**, **Type**, **Environment** and **Name** (or leave **ALL** to include all options). Alternatively, you can select **Use KQL Filter** and enter a KQL expression to limit the scope of your rule.
. Define the threshold and period:
+
** **When**: Choose between `Average`, `95th percentile`, or `99th percentile`.
** **Is Above**: Enter a time in milliseconds (defaults to 1500ms).
** **For the last**: Define the period to be assessed in (defaults to last 5 minutes).
. Choose how to **Group alerts by**. Every unique value will create an alert.
. Define the interval to check the rule (for example, check every 1 minute).
. (Optional) Set up **Actions**.
. **Save** your rule.

[discrete]
[[observability-create-latency-threshold-alert-rule-add-actions]]
== Add actions

You can extend your rules with actions that interact with third-party systems, write to logs or indices, or send user notifications. You can add an action to a rule at any time. You can create rules without adding actions, and you can also define multiple actions for a single rule.

To add actions to rules, you must first create a connector for that service (for example, an email or external incident management system), which you can then use for different rules, each with their own action frequency.

.Connector types
[%collapsible]
=====
Connectors provide a central place to store connection information for services and integrations with third party systems.
The following connectors are available when defining actions for alerting rules:

include::./alerting-connectors.asciidoc[]

For more information on creating connectors, refer to <<action-connectors,Connectors>>.
=====

.Action frequency
[%collapsible]
=====
After you select a connector, you must set the action frequency. You can choose to create a **Summary of alerts** on each check interval or on a custom interval. For example, you can send email notifications that summarize the new, ongoing, and recovered alerts every twelve hours.

Alternatively, you can set the action frequency to **For each alert** and specify the conditions each alert must meet for the action to run. For example, you can send an email only when the alert status changes to critical.

[role="screenshot"]
image::images/alert-action-frequency.png[Configure when a rule is triggered]

With the **Run when** menu you can choose if an action runs when the threshold for an alert is reached, or when the alert is recovered. For example, you can add a corresponding action for each state to ensure you are alerted when the rule is triggered and also when it recovers.

[role="screenshot"]
image::images/alert-apm-action-frequency-recovered.png[Choose between threshold met or recovered]
=====

.Action variables
[%collapsible]
=====
Use the default notification message or customize it.
You can add more context to the message by clicking the Add variable icon image:images/icons/indexOpen.svg[Add variable] and selecting from a list of available variables.

[role="screenshot"]
image::images/action-variables-popup.png[Action variables list]

The following variables are specific to this rule type.
You can also specify {kibana-ref}/rule-action-variables.html[variables common to all rules].

`context.alertDetailsUrl`::
Link to the alert troubleshooting view for further context and details. This will be an empty string if the `server.publicBaseUrl` is not configured.

`context.environment`::
The transaction type the alert is created for.

`context.interval`::
The length and unit of time period where the alert conditions were met.

`context.reason`::
A concise description of the reason for the alert.

`context.serviceName`::
The service the alert is created for.

`context.threshold`::
Any trigger value above this value will cause the alert to fire.

`context.transactionName`::
The transaction name the alert is created for.

`context.transactionType`::
The transaction type the alert is created for.

`context.triggerValue`::
The value that breached the threshold and triggered the alert.

`context.viewInAppUrl`::
Link to the alert source.

=====

[discrete]
[[create-latency-transaction-rate-threshold-example]]
== Example

The latency threshold alert triggers when the latency of a specific transaction type in a service exceeds a defined threshold.

Before continuing, identify the service name, environment name, and transaction type that you’d like to create a latency threshold rule for.

This guide will create an alert for an error group ID based on the following criteria:

* Service: `{your_service.name}`
* Transaction: `{your_transaction.name}`
* Environment: `{your_service.environment}`
* Average latency is above 1500ms for last 5 minutes
* Group alerts by `service.name` and `service.environment`
* Check every 1 minute
* Send the alert via email to the site reliability team

From any page in **Applications**, select **Alerts and rules** → **Create threshold rule** → **Latency threshold**. Change the name of the alert (if you wish), but do not edit the tags.

Based on the criteria above, define the following rule details:

* **Service**: `{your_service.name}`
* **Type**: `{your_transaction.name}`
* **Environment**: `{your_service.environment}`
* **When:** `Average`
* **Is above:** `1500ms`
* **For the last:** `5 minutes`
* **Group alerts by:** `service.name` `service.environment`
* **Check every:** `1 minute`

Next, select the **Email** connector and click **Create a connector**. Fill out the required details: sender, host, port, etc., and select **Save**.

A default message is provided as a starting point for your alert. You can use the Mustache template syntax (`{{variable}}`) to pass additional alert values at the time a condition is detected to an action. A list of available variables can be accessed by selecting the add variable button.

Select **Save**. The alert has been created and is now active!
