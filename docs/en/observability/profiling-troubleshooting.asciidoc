[[profiling-troubleshooting]]
= Troubleshoot your Universal Profiling 

++++
<titleabbrev>Troubleshoot</titleabbrev>
++++

beta::[]

You can use the host-agent logs to find errors.

The following is an example of a _healthy_ host-agent output:

[source,logs]
----
time="..." level=info msg="Starting Prodfiler Host Agent v2.4.0 (revision develop-5cce978a, build timestamp 12345678910)"
time="..." level=info msg="Interpreter tracers: perl,php,python,hotspot,ruby,v8"
time="..." level=info msg="Automatically determining environment and machine ID ..."
time="..." level=warning msg="Environment tester (gcp) failed: failed to get GCP metadata: Get \"http://169.254.169.254/computeMetadata/v1/instance/id\": dial tcp 169.254.169.254:80: i/o timeout"
time="..." level=warning msg="Environment tester (azure) failed: failed to get azure metadata: Get \"http://169.254.169.254/metadata/instance/compute?api-version=2020-09-01&format=json\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="..." level=warning msg="Environment tester (aws) failed: failed to get aws metadata: EC2MetadataRequestError: failed to get EC2 instance identity document\ncaused by: RequestError: send request failed\ncaused by: Get \"http://169.254.169.254/latest/dynamic/instance-identity/document\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="..." level=info msg="Environment: hardware, machine ID: 0xdeadbeefdeadbeef"
time="..." level=info msg="Assigned ProjectID: 5"
time="..." level=info msg="Start CPU metrics"
time="..." level=info msg="Start I/O metrics"
time="..." level=info msg="Found tpbase offset: 9320 (via x86_fsbase_write_task)"
time="..." level=info msg="Environment variable KUBERNETES_SERVICE_HOST not set"
time="..." level=info msg="Supports eBPF map batch operations"
time="..." level=info msg="eBPF tracer loaded"
time="..." level=info msg="Attached tracer program"
time="..." level=info msg="Attached sched monitor"
----

A host-agent deployment is working if the output of the following command is empty:

[source,logs]
----
head host-agent.log -n 15 | grep "level=error"
----

If running this command outputs error-level logs, the following are possible causes:

* The host-agent is running on an unsupported version of the Linux kernel, or its missing kernel features.
+
If the host-agent is running on an unsupported kernel version, the following is logged:
+
[source,logs]
----
Host Agent requires kernel version 4.15 or newer but got 3.10.0
----
+
If eBPF features are not available in the kernel, the host-agent fails to start, and one of the following is logged:
+
[source,logs]
----
Failed to probe eBPF syscall
----
+
or
+
[source,logs]
----
Failed to probe tracepoint
----
* The host-agent is not able to connect to {ecloud}. In this case, a similar message to the following is logged:
+
[source,logs]
----
Failed to setup gRPC connection (retrying...): context deadline exceeded
----
+
Verify the `collection-agent` configuration value is set and is equal to what was printed  in Kibana, when clicking to *Add Data*.
* The secret token is not valid, or it has been changed. In this case, the host-agent shuts down, and logs a similar message to the following:
+
[source,logs]
----
rpc error: code = Unauthenticated desc = authentication failed
----
* The host-agent is unable to send data to your deployment. In this case, a similar message to the following is logged:
+
[source,logs]
----
Failed to report hostinfo (retrying...): rpc error: code = Unimplemented desc = unknown service collectionagent.CollectionAgent"
----
+
This typically means that your {ecloud} cluster has not been configured for Universal Profiling. To configure your {ecloud} cluster, follow the steps in <<profiling-configure-data-ingestion,configure data ingestion>>.
* The APM server (part of the backend in {ecloud} that receives data from the host-agent) ran out of memory. In this case, a similar message to the following is logged:
+
[source,logs]
----
Error: failed to invoke XXX(): Unavailable rpc error: code = Unavailable desc = unexpected HTTP status code received from server: 502 (Bad Gateway); transport: received unexpected content-type "application/json; charset=UTF-8"
----
+
Verify that the APM server is running by navigating to *{ecloud} → Deployments → `<Deployment Name>` → Integrations Server* in https://cloud.elastic.co/home[Elastic Cloud]. If the *Copy endpoint* link next to *APM* is grayed out,
you need to restart the APM server by clicking *Force Restart* under *Integrations Server Management*.
+
For non-demo workloads, verify that the Integrations Server has at least the recommended 4GB of RAM. You can check this on the Integrations Server page under *Instances*.
* The host-agent is incompatible with the {stack} version. In this case, the following message is logged:
+
[source,logs]
----
rpc error: code = FailedPrecondition desc= HostAgent version is unsupported, please upgrade to the latest version
----
+
Follow the host-agent deployment instructions shown in Kibana which will always be correct for the {stack} version that you are using.

If you're unable to find a solution to the host-agent failure, you can raise a support request indicating `Universal Profiling` and `host-agent` as the source of the problem.

[discrete]
[[profiling-enable-verbose-logging]]
== Enable verbose logging in host-agent

During the support process, you may be asked to provide debug logs from one of the host-agent installations from your
deployment.

To enable debug logs, add the `-verbose` command-line flag or the `verbose true` setting in the configuration file.

NOTE: We recommend only enabling debug logs on a single instance of host-agent rather than an entire deployment to limit the amount of logs produced.

[discrete]
[[profiling-improve-load-time]]
== Improve load times

The amount of data loaded for the flamegraph, topN functions, and traces view can lead to latency when using a slow connection (e.g. DSL or mobile).

Setting the Kibana cluster option `server.compression.brotli.enabled: true` reduces the amount of data transferred and should reduce load time.

[discrete]
[[profiling-troubleshoot-kubernetes]]
== Troubleshoot host-agent {k8s} deployments

When the Helm chart installation finishes, the output has instructions on how to check the host-agent pod status and read logs.
The following sections provide potential scenarios when host-agent installation *is not healthy*.

[discrete]
[[profiling-taints]]
=== Taints

{k8s} clusters often include https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/[taints and tolerations] in their setup.
In these cases, a host-agent installation may show no pods or very few pods running, even for a large cluster.

This is because a taint precludes the execution of pods on a node unless the workload has been tolerated.
The Helm chart `tolerations` key in the `values.yaml` sets the toleration of taints using the official {k8s} scheduling API
format.

The following examples provide a `tolerations` config that you can add to the Helm chart `values.yaml`:

* To deploy the host-agent on all nodes with taint `workload=python:NoExecute`, add the following to the `values.yaml`:
+ 
[source,yaml]
----
tolerations:
- key: "workload"
  value: "python"
  effect: "NoExecute"
----
* To deploy the host-agent on all nodes tainted with _key_ `production` and effect `NoSchedule` (no value provided), add the following to the `values.yaml`:
+
[source,yaml]
----
tolerations:
  - key: "production"
    effect: "NoSchedule"
    operator: Exists
----
* To deploy the host-agent on all nodes, tolerating all taints, add the following to the `values.yaml`:
+
[source,yaml]
----
tolerations:
  - effect: NoSchedule
    operator: Exists
  - effect: NoExecute
    operator: Exists
----

[discrete]
[[profiling-security-policy-enforcement]]
=== Security policy enforcement

Some {k8s} clusters are configured with hardened security add-ons to limit the blast radius of exploited application vulnerabilities. 
Different hardening methodologies can impair host-agent operations and may, for example, result in pods continuously restarting after displaying a `CrashLoopBackoff` status.

[discrete]
[[profiling-kubernetes-podsecuritypolicy]]
==== {k8s} PodSecurityPolicy (https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/[deprecated])

This {k8s} API has been deprecated, but some still use it. A PodSecurityPolicy (PSP) may explicitly prevent the execution of `privileged` containers across the entire cluster.

Since host-agent _needs_ privileges in most kernels/CRI, you need to build a PSP to allow the host-agent DaemonSet to run.

[discrete]
[[profiling-policy-engines]]
==== {k8s} policy engines

Read more about {k8s} policy engines in the https://github.com/kubernetes/sig-security/blob/main/sig-security-docs/papers/policy/kubernetes-policy-management.md[SIG-Security documentation].

The following tools _may_ prevent the execution of host-agent pods as the Helm chart builds a cluster role and binds it into the host-agent service account (we use it for container metadata):

* Open Policy Agent Gatekeeper
* Kyverno
* Fairwinds Polaris

If you have a policy engine in place, configure it to allow the host-agent execution and RBAC configs.

[discrete]
[[profiling-network-config]]
==== Network configurations

In some instances, your host-agent pods may be running fine, but they will not connect to the remote data collector gRPC interface and stay in the startup phase, while trying to connect periodically.

The following are potential causes:

* {k8s} https://kubernetes.io/docs/concepts/services-networking/network-policies/[`NetworkPolicies`] define connectivity rules that prevent all outgoing traffic unless explicitly allow-listed.
* Cloud or datacenter provider network rules are restricting egress traffic to allowed destinations only (ACLs).

[discrete]
[[profiling-os-level-security]]
==== OS-level security

These settings _are not part of {k8s}_ and may have been included in the node setup. They can prevent the host-agent from working properly, as they intercept syscalls from the host-agent to the kernel and modify or block them.

If you have implemented security hardening (some providers listed below), you should know the privileges the host-agent needs.

* gVisor on GKE
* seccomp filters
* AppArmor LSM


[discrete]
[[profiling-submit-support]]
== Submit a support request

You can submit a support request from the https://cloud.elastic.co/support[support request page] in the {ecloud} console.

In the support request, specify if your issue deals with the host-agent or the Kibana app.

[discrete]
[[profiling-send-feedback]]
== Send feedback

If troubleshooting and support are not fixing your issues, or you have any other feedback that you want to share about the
product, send the Universal Profiling team an email at `profiling-feedback@elastic.co`.