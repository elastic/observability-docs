[[quickstart-monitor-hosts-with-elastic-agent]]
= Quickstart: Monitor hosts with {agent}

preview::[]

In this quickstart guide, you'll learn how to scan your host to detect and collect logs and metrics,
then navigate to dashboards to further analyze and explore your observability data.
You'll also learn how to get value out of your observability data.

To scan your host, you'll run an auto-detection script that downloads and installs {agent},
which is used to collect observability data from the host and send it to Elastic.

The script also generates an {agent} configuration file that you can use with your existing Infrastructure-as-Code tooling.

[discrete]
== Prerequisites

* A deployment using our hosted {ess} on {ess-trial}[{ecloud}]. The deployment includes an {es} cluster for storing and searching your data, and {kib} for visualizing and managing your data.
* A user with the `superuser` {ref}/built-in-roles.html[built-in role] or the privileges required to onboard data.
+
[%collapsible]
.Expand to view required privileges
====
* {ref}/security-privileges.html#privileges-list-cluster[**Cluster**]: `['monitor', 'manage_own_api_key']`
* {ref}/security-privileges.html#privileges-list-indices[**Index**]: `{ names: ['logs-*-*', 'metrics-*-*'], privileges: ['auto_configure', 'create_doc'] }`
* {kibana-ref}/kibana-privileges.html[**Kibana**]: `{ spaces: ['*'], feature: { fleet: ['all'], fleetv2: ['all'] } }`
====
* Root privileges on the hostâ€”required to run the auto-detection script used in this quickstart.

[discrete]
== Limitations

* The auto-detection script currently scans for metrics and logs from Apache, Docker, Nginx, and the host system.
   It also scans for custom log files.
* The auto-detection script works on Linux and MacOS only. Support for the `lsof` command is also required if you want to detect custom log files.
* If you've installed Apache or Nginx in a non-standard location, you'll need to specify log file paths manually when you run the scan.
* Because Docker Desktop runs in a VM, its logs are not auto-detected.

[discrete]
== Collect your data

. Go to the **Observability** UI and click **Add Data**.
. Select **Collect and analyze logs**, and then select **Auto-detect logs and metrics**.
. Copy the command that's shown. For example:
+
[role="screenshot"]
image::images/quickstart-autodetection-command.png[Quick start showing command for running auto-detection]
+
You'll run this command to download the auto-detection script and scan your system for observability data.
. Open a terminal on the host you want to scan, and run the command.
. Review the list of log files:
    * Enter `Y` to ingest all the log files listed.
    * Enter `n` to either exclude log files or specify additional log paths. Enter `Y` to confirm your selections.

When the script is done, you'll see a message like "{agent} is configured and running."

There might be a slight delay before logs and other data are ingested.

*****
**Need to scan your host again?**

You can re-run the script on the same host to detect additional logs.
The script will scan the host and reconfigure {agent} with any additional logs that are found.
If the script misses any custom logs, you can add them manually by entering `n` after the script has finished scanning the host.
*****

[discrete]
== Visualize your data

After installation is complete and all relevant data is flowing into Elastic,
the **Visualize your data** section will show links to assets you can use to analyze your data.
Depending on what type of observability data was collected,
the page may link to the following integration assets:

|====
| Integration asset | Description

| **System**
| Prebuilt dashboard for monitoring host status and health using system metrics.

| **Apache**
| Prebuilt dashboard for monitoring Apache HTTP server health using error and access log data.


| **Docker**
| Prebuilt dashboard for monitoring the status and health of Docker containers.


| **Nginx**
| Prebuilt dashboard for monitoring Nginx server health using error and access log data.


| **Custom .log files**
| Logs Explorer for analyzing custom logs.
|====

For example, you can navigate the **Host overview** dashboard to explore detailed metrics about system usage and throughput.
Metrics that indicate a possible problem are highlighted in red.

[role="screenshot"]
image::images/quickstart-host-overview.png[Host overview dashboard]

[discrete]
== Get value out of your data

After using the dashboards to examine your data and confirm you've ingested all the host logs and metrics you want to monitor,
you can use Elastic {observability} to gain deeper insight into your data.

For host monitoring, the following capabilities and features are recommended:

* In the <<analyze-metrics,Infrastructure UI>>, analyze and compare data collected from your hosts.
You can also:
** <<inspect-metric-anomalies,Detect anomalies>> for memory usage and network traffic on hosts.
** <<create-alerts,Create alerts>> that notify you when an anomaly is detected or a metric exceeds a given value.
* In the <<explore-logs,Logs Explorer>>, search and filter your log data,
get information about the structure of log fields, and display your findings in a visualization.
You can also:
** <<monitor-datasets,Monitor log data set quality>> to find degraded documents.
** {kibana-ref}/xpack-ml-aiops.html#log-pattern-analysis[Run a pattern analysis] to find patterns in unstructured log messages.
** <<create-alerts,Create alerts>> that notify you when an Observability data type reaches or exceeds a given value.
* Use {kibana-ref}/xpack-ml.html[machine learning] to apply predictive analytics to your data:
** {kibana-ref}/xpack-ml-anomalies.html[Detect anomalies] by comparing real-time and historical data from different sources to look for unusual, problematic patterns.
** {kibana-ref}/xpack-ml-aiops.html#log-rate-analysis[Analyze log spikes and drops].
** {kibana-ref}/xpack-ml-aiops.html#change-point-detection[Detect change points] in your time series data.

Refer to the <<observability-introduction>> for a description of other useful features.
