[[slo-burn-rate-alert]]
= Create a service-level objective (SLO) burn rate rule

++++
<titleabbrev>Create an SLO burn rate rule</titleabbrev>
++++

beta::[]

include::slo-overview.asciidoc[tag=slo-license]

You can create a SLO burn rate rule to get alerts when the burn rate is above a defined threshold for two different lookback periods: a long period and a short period that is 1/12th of the long period.
For example, if your long lookback period is one hour, your short lookback period is five minutes.

For each lookback period, the burn rate is computed as the error rate divided by the error budget.
When the burn rates for both periods surpass the threshold, an alert is triggered.

To create an SLO burn rate rule, go to *Observability â†’ SLOs*. Click the more options icon to the right of the SLO you want to add a burn rate rule for, and select *Create new alert rule* from the drop-down menu:

[role="screenshot"]
image::images/create-new-alert-rule-menu.png[]

To create your SLO burn rate rule:

. Set your long lookback period under *Lookback period (hours)*. Your short lookback period is set automatically.
. Set your *Burn rate threshold*. Under this field, you'll see how long you have until your error budget is exhausted.
. Set how often the condition is evaluated in the *Check every* field.

[discrete]
[[action-types-slo]]
== Action types

You can extend your rules by connecting them to actions that use the following
supported built-in integrations. Actions are {kib} services or integrations with
third-party systems that run as background tasks on the {kib} server when rule conditions are met.

You can configure action types on the <<configure-uptime-alert-connectors,Settings>> page.

[role="screenshot"]
image::images/alert-action-types.png[Uptime rule connectors]

After you select a connector, you must set the action frequency. You can choose to create a *Summary of alerts* on each check interval or on a custom interval. For example, you can send email notifications that summarize the new, ongoing, and recovered alerts every twelve hours.

Alternatively, you can set the action frequency to *For each alert* and specify the conditions each alert must meet for the action to run. For example, you can send an email only when the alert status changes to critical.

[role="screenshot"]
image::images/slo-action-frequency.png[Configure when a rule is triggered]

[discrete]
[[action-variables-slo]]
== Action variables

Use the default notification message or customize it.
You can add more context to the message by clicking the icon above the message text box
and selecting from a list of available variables.

[role="screenshot"]
image::images/slo-action-variables.png[Action variables with default SLO message]

[discrete]
[[recovery-variables-slo]]
== Alert recovery

To receive a notification when the alert recovers, select *Run when Recovered*. Use the default notification message or customize it. You can add more context to the message by clicking the icon above the message text box and selecting from a list of available variables.

[role="screenshot"]
image::images/duration-anomaly-alert-recovery.png[Default recovery message for Uptime duration anomaly rules with open "Add variable" popup listing available action variables,width=600]