[[logs-stream]]
= Stream a log file

In this guide, you'll learn how to take a log file from your host and send it to Elasticsearch using a standalone {agent}. You'll configure the {agent} and your data streams using the Custom Logs integration. From there, you'll learn how to query your logs and use the data streams you've set up to have more control and flexibility when filtering your log data. 

[discrete]
[[logs-stream-prereq]]
= Prerequisites

include::logs-metrics-get-started.asciidoc[tag=monitoring-prereqs]

[discrete]
[[logs-stream-install-config-agent]]
= Install and configure the standalone {agent}

To install and configure the standalone {agent} to send your log data to {es}, you need to complete a few steps:

. Download and extract the {agent} installation package.
. Configure the {agent} using the Custom Logs integration.
. Install and start the {agent}.

[discrete]
[[logs-stream-extract-agent]]
== Step 1: Download and extract the {agent} installation package

On your host, download and extract the installation package:

include::{ingest-docs-root}/docs/en/ingest-management/tab-widgets/download-widget.asciidoc[]

[discrete]
[[logs-stream-agent-config]]
== Step 2: Configure the {agent}

You can use the Custom Logs integration in {kib} to create and download an {agent} policy. 
Your agent policy sets the path to your log file and sets up your data streams.

Complete the following steps to create and download your {agent} policy:

. Go to the {kib} home page and click *Add integrations*:
+
--
[role="screenshot"]
image::images/add-integrations.png[{kib} home page]
--

. In the search bar, search for *custom* and select *Custom Logs*.
. Click *Add Custom Logs* in the upper-right corner:
+
--
[role="screenshot"]
image::images/add-custom-logs.png[add custom logs button location]
--

. Click *Install {agent}*.
. Click *standalone mode*:
+
--
[role="screenshot"]
image::images/standalone-link.png[link to running agents in standalone mode]
--
. Add the path to your log file in the *Log file path* field and click *Save and continue*.
. Set the name for your dataset data stream in the *Dataset name* field. The dataset name describes the data ingested and its structure. This field can contain anything that signifies the source of the data. The default value is `generic`.
. Click *Advanced options* to open the *Integration settings*.
+
--
[role="screenshot"]
image::images/custom-log-advanced-options.png[open integration settings]
--
. Set the name for your namespace data stream in the *Namespace* field. The namespace is useful for grouping data such as an environment (dev, prod, or qa), a team, or a strategic business unit. Using a namespace makes it easier to search data from a given source by using a matching pattern. The default value is `default`.
. Click *Copy to clipboard* and paste the configuration in the `elastic-agent.yml` file located on your host where you extracted your {agent} installation package.
. Replace `ES_USERNAME` and `ES_PASSWORD` in the policy with your Elasticsearch credentials.

[discrete]
[[logs-stream-install-agent]]
== Step 3: Install and start the {agent}
With your configuration set, you're ready to install the {agent}. From the agent directory, run the the 
command that corresponds with your system to install the {agent} and start it as a service.

NOTE: On macOS, Linux (tar package), and Windows, run the `install` command to
install {agent} as a managed service and start the service. The DEB and RPM
packages include a service unit for Linux systems with
systemd, so just enable then start the service.

include::{ingest-docs-root}/docs/en/ingest-management/tab-widgets/run-standalone-widget.asciidoc[]

[discrete]
[[logs-stream-query-datastreams]]
== View and search your data

With your {agent} and data streams set up, you can filter and search your log data. In {kib}, navigate to *Observability → Logs → Stream*, and use the search bar to search for your `data_stream.type`, `data_stream.dataset`, and `data_stream.namespace`. 

See the following examples for ways to search specific data types, datasets, or namespaces:

- `data_stream.type: logs` to show `logs` data streams.
- `data_stream.dataset: nginx.access` shows data streams with an `nginx.access` dataset.
- `data_stream.type: logs AND data_stream.namespace: web-frontend` shows data streams with a type of `logs` and a namespace of `web-frontend`

For more information, see {fleet-guide}/data-streams.html#data-streams[Data streams].