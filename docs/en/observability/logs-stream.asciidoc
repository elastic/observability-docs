[[logs-stream]]
= Stream a log file

In this guide, you'll learn how to take a log file from your host and send it to Elasticsearch using a standalone {agent}. You'll configure the {agent} and your data streams using the Custom Logs integration. From there, you'll learn how to query your logs and use the data streams you've set up to have more control and flexibility when filtering your log data. 

[discrete]
[[logs-stream-prereq]]
= Prerequisites

include::logs-metrics-get-started.asciidoc[tag=monitoring-prereqs]

[discrete]
[[logs-stream-install-config-agent]]
= Install and configure the standalone {agent}

Install and configure the standalone {agent} to send your log data to {es} by completing the following steps:

. Download and extract the {agent} installation package.
. Configure the {agent} using the Custom Logs integration.
. Install and start the {agent}.

[discrete]
[[logs-stream-extract-agent]]
== Step 1: Download and extract the {agent} installation package

On your host, download and extract the installation package that corresponds with your system:

include::{ingest-docs-root}/docs/en/ingest-management/tab-widgets/download-widget.asciidoc[]

[discrete]
[[logs-stream-agent-config]]
== Step 2: Configure the {agent}

Configure the {agent} by updating the 'elastic-agent.yml' in the folder where you extracted the installation package.

The following is an example of a simple standalone {agent} configuration:

[source,yaml]
----
outputs:
  default:
    type: elasticsearch
    hosts: '<your-elasticsearch-url>:<port>'
    api_key: 'your-api-key'
inputs:
  - id: your-log-id
    type: logfile
    data_stream:
      namespace: default
    streams:
      - id: your-log-stream-id
        data_stream:
          dataset: generic
        paths:
          - /var/log/your-logs.log
----

To configure your {agent}, set the values for the fields in the example configuration:

. `hosts` – Your {es} URL and the port.
. `api-key` – An API key to grant the agent access to {es}. To create an API key for your agent, see {fleet-guide}/grant-access-to-elasticsearch.html#create-api-key-standalone-agent[Create API keys for standalone agents].
+
NOTE: The API key format should be <id>:<key>. Make sure you selected *Beats* when you created your API key. Base64 encoded API keys are not currently supported in this configuration.
. `inputs.id` – A unique identifier for your input.
. `type` – The type of input. For collectings logs, set this to `logfile`.
. `data_stream.namespace` – The name for your namespace data stream. The namespace is useful for grouping data such as an environment (dev, prod, or qa), a team, or a strategic business unit. Using a namespace makes it easier to search for data from a given source by using a matching pattern. The default value is `default`.
. `streams.id` – A unique identifier for your stream of log data. 
. `data_stream.dataset` – the name for your dataset data stream. You can name this data stream anything that signifies the source of the data. The default value is `generic`.
. `paths` – the path to your log file.

[discrete]
[[logs-stream-install-agent]]
== Step 3: Install and start the {agent}
With your configuration set, you're ready to install the {agent}. From the agent directory, run the the command that corresponds with your system to install the {agent} as a service. Do *not* enroll the agent in Fleet.

NOTE: On macOS, Linux (tar package), and Windows, run the `install` command to
install {agent} as a managed service and start the service. The DEB and RPM
packages include a service unit for Linux systems with
systemd, so just enable then start the service.

include::{ingest-docs-root}/docs/en/ingest-management/tab-widgets/run-standalone-widget.asciidoc[]

[discrete]
[[logs-stream-query-datastreams]]
= View and search your data

With your {agent} and data streams configured, you can now view, filter, and search your log data. In {kib}, navigate to *Observability → Logs → Stream*, and use the search bar to search for your `data_stream.type`, `data_stream.dataset`, and `data_stream.namespace`. 

See the following examples for ways to search specific data types, datasets, or namespaces:

- `data_stream.type: logs` shows `logs` data streams.
- `data_stream.dataset: nginx.access` shows data streams with an `nginx.access` dataset.
- `data_stream.namespace: web-frontend` shows data streams with `web-frontend` namespace.

The following example shows the search results for logs with an `apm.error` dataset and a `default` namespace:

--
[role="screenshot"]
image::images/stream-logs-example.png[example search query on the logs stream page in {kib}]
--

[discrete]
[[logs-stream-troubleshooting]]
= Troubleshooting 

If you're not seeing your log files in {kib}, check the following in the `elastic-agent.yml` file:

NOTE: After installing the {agent}, you need to update the `elastic-agent.yml` in the directory described in the {fleet-guide}/installation-layout.html[installation layout].

- Verify that the path to your logs file under `paths` is correct.
- Verify that your API key is in <id>:<key> format. If not, your API key may be in an unsupported format, and you'll need to create an API key in *Beats* format. 

[discrete]
[[logs-stream-whats-next]]
= What's next?

For more information on deploying and managing logs in Elastic Observability, see the following links:

- The <<logs-checklist>> consolidates links to documentation on sending log data, configuring logs, and analyzing logs.
- <<monitor-logs>> has information on visualizing and analyzing logs.