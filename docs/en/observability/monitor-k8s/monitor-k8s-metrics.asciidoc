[discrete]
[[monitor-kubernetes-health-and-performance-metrics]]
== Part 2: Monitor health and performance metrics

Collecting metrics about Kubernetes clusters and the workloads running on top of
them is a key aspect of Kubernetes observability. However, collecting metrics
from Kubernetes poses some challenges. You need to collect metrics about the
resources running on "physical" machines as well as the containers and pods.
Specifically, you need to monitor the health and performance of:

* The hosts where Kubernetes components are running. Each host produces metrics
like CPU, memory, disk utilization, and disk and network I/O.

* Kubernetes containers, which produce their own set of metrics.

* The applications running as Kubernetes pods, such as application servers and
databases, each producing its own set of metrics.

Instead of using multiple technologies to collect metrics, you deploy
{metricbeat} to monitor all layers of your technology stack.

[discrete]
=== Deploy {metricbeat} to collect metrics

You'll use {metricbeat} to collect metrics from pods running in your Kubernetes
cluster as well as metrics from the Kubernetes cluster itself.

{metricbeat} modules provide a quick and easy way to pick up metrics from
various sources and ship them to {es} as {ecs-ref}/index.html[ECS]-compatible
events, ready to be correlated with logs, uptime, and APM data.

To deploy {metricbeat} to your Kubernetes cluster:

[discrete]
==== Step 1: Download the {metricbeat} deployment manifest

To make deployment easier, Elastic provides a YAML file that defines all the
required deployment settings. In many cases, you can change the connection
details and deploy with default settings to get started quickly.

["source", "sh", subs="attributes"]
------------------------------------------------
curl -L -O https://raw.githubusercontent.com/elastic/beats/{branch}/deploy/kubernetes/metricbeat-kubernetes.yaml
------------------------------------------------


[discrete]
==== Step 2: Set the connection information for {es}

{metricbeat} sends events to an existing {es} deployment, if present.
To specify a different destination, change the following parameters in the
`metricbeat-kubernetes.yaml` file:

[source,yaml]
----
env:
- name: ELASTICSEARCH_HOST
  value: elasticsearch
- name: ELASTICSEARCH_PORT
  value: "9200"
- name: ELASTICSEARCH_USERNAME
  value: elastic <1>
- name: ELASTICSEARCH_PASSWORD
  value: changeme
- name: ELASTIC_CLOUD_ID <2>
  value:
- name: ELASTIC_CLOUD_AUTH <2>
  value:
----
<1> This user must have the privileges required to publish events to {es}. For
more information, see {metricbeat-ref}/feature-roles.html[Grant users access to secured resources].
<2> Use the cloud settings if you're sending data to {ess} on {ecloud}.

To avoid exposing sensitive data, you can base64 encode the string, then store
it in a Kubernetes secret. For example:

["source", "sh", subs="attributes"]
------------------------------------------------
$ echo -n 'changeme' | base64
Y2hhbmdlbWU=
$ kubectl create secret generic es-secret --from-literal=password='Y2hhbmdlbWU=' --namespace=kube-system <1>
------------------------------------------------
<1> Create the secret in the namespace where you will deploy {metricbeat}.

To use the secret, change the env setting in the manifest file:

[source,yaml]

------------------------------------------------
env:
- name: ELASTICSEARCH_PASSWORD
  valueFrom:
    secretKeyRef:
      name: es-secret
      key: password
------------------------------------------------

[discrete]
==== Step 3: Mount paths

{metricbeat} will run on each node in the cluster as a Daemonset's pod.
To collect system-level metrics, key paths are mounted from the host to the pod:

[source,yaml]
------------------------------------------------
- name: proc
  hostPath:
  path: /proc
- name: cgroup
  hostPath:
  path: /sys/fs/cgroup
------------------------------------------------

[discrete]
==== Step 4: Collect system metrics

To collect system-level metrics from the running node, configure the `system`
module. The metricsets that you're likely to want are already enabled in the
manifest. Modify the settings as required for your environment: 

[source,yaml]
------------------------------------------------
- module: system
  period: 10s
  metricsets:
    - cpu
    - load
    - memory
    - network
    - process
    - process_summary
------------------------------------------------

[discrete]
==== Step 5: Collect metrics from each Kubernetes node

Because {metricbeat} is running on each node, you can collect metrics from the
Kubelet API. These metrics provide important information about the state of the
Kubernetes node, pods, containers, and other resources. 

To collect these metrics, configure the `kubernetes` module. The metricsets that
you're likely to want are already enabled in the manifest. Modify the settings
as required for your environment:

[source,yaml]
------------------------------------------------
- module: kubernetes
  metricsets:
    - node
    - system
    - pod
    - container
    - volume
------------------------------------------------

These metricsets collect metrics from the Kubelet API and therefore require
access to the specific endpoints. Depending on the version and configuration of
Kubernetes nodes, kubelet might provide a read-only HTTP port (typically
10255), which is used in some configuration examples. But in general, and
lately, this endpoint requires SSL (HTTPS) access (to port 10250 by default) and
token-based authentication.

[discrete]
==== Step 6: Collect Kubernetes state metrics

{metricbeat} gets some metrics from
https://github.com/kubernetes/kube-state-metrics#usage[kube-state-metrics].
If kube-state-metrics is not already running, deploy it now. To learn how,
see the Kubernetes deployment
https://github.com/kubernetes/kube-state-metrics#kubernetes-deployment[docs].

To collect state metrics:

. Enable metricsets that begin with the `state_` prefix. The metricsets that
you're likely to want are already enabled in the manifest.

. Set the `hosts` field to point to the kube-state-metrics service within the
cluster.

Because the kube-state-metrics service provides cluster-wide metrics, there’s no
need to fetch them per node. To use this singleton approach, {metricbeat}
leverages a leader election method, where one pod holds a leader lock and is
responsible for collecting cluster-wide metrics. For more information about
leader election settings, see
{metricbeat-ref}/configuration-autodiscover.html[Autodiscover]. 

[source,yaml]
------------------------------------------------
metricbeat.autodiscover:
    providers:
    - type: kubernetes
      scope: cluster
      node: ${NODE_NAME}
      unique: true
      templates:
        - config:
            - module: kubernetes
              hosts: ["kube-state-metrics:8080"]
              period: 10s
              add_metadata: true
              metricsets:
                - state_node
                - state_deployment
                - state_daemonset
                - state_replicaset
                - state_pod
                - state_container
                - state_cronjob
                - state_resourcequota
                - state_statefulset
------------------------------------------------

NOTE: If your Kubernetes cluster contains a large number of large nodes, the pod
that collects cluster-level metrics might face performance issues caused by
resource limitations. In this case, avoid using the leader election strategy and
instead run a dedicated, standalone {metricbeat} instance using a Deployment in
addition to the DaemonSet.

[discrete]
==== Step 7: Collect application-specific metrics (use hint-based autodiscovery)

{metricbeat} supports autodiscovery based on hints from the provider. The hints
system looks for hints in Kubernetes pod annotations or Docker labels that have
the prefix `co.elastic.metrics`. When a container starts, {metricbeat} checks
for hints and launches the proper configuration. The hints tell {metricbeat} how
to get metrics for the given container. To enable hint-based autodiscovery, set
`hints.enabled: true`:

[source,yaml]
------------------------------------------------
metricbeat.autodiscover:
  providers:
    - type: kubernetes
      hints.enabled: true
------------------------------------------------

By labeling Kubernetes pods  with the `co.elastic.metrics` prefix you can signal {metricbeat} to collect metrics from those pods using the appropriate modules:

[source,yaml]
------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
    name: nginx-autodiscover
    annotations:
        co.elastic.metrics/module: nginx
        co.elastic.metrics/metricsets: stubstatus
        co.elastic.metrics/hosts: '${data.host}:80'
        co.elastic.metrics/period: 10s
------------------------------------------------

[discrete]
==== Step 8: Collect metrics from Prometheus

To enrich your collection resources, you can use the `prometheus` module to
collect metrics from every application that runs on the cluster and exposes a
Prometheus exporter. For instance, let's say that the cluster runs multiple
applications that expose Prometheus metrics with the default Prometheus
standards. Assuming these applications are annotated properly, you can define
an extra autodiscovery provider to automatically identify the applications and
start collecting exposed metrics by using the `prometheus` module:

[source,yaml]
------------------------------------------------
metricbeat.autodiscover:
  providers:
    - type: kubernetes
      include_annotations: ["prometheus.io.scrape"]
      templates:
        - condition:
            contains:
              kubernetes.annotations.prometheus.io/scrape: "true"
          config:
            - module: prometheus
              metricsets: ["collector"]
              hosts: "${data.host}:${data.port}"
------------------------------------------------

This configuration launches a `prometheus` module for all containers of pods
annotated with `prometheus.io/scrape: "true"`.

[discrete]
==== Step 9: Add metadata to events

{metricbeat} provides processors that you can use in your configuration to
enrich events with metadata coming from Docker, Kubernetes, hosts, and cloud
providers.

The `add_cloud_metadata` and `add_host_metadata` processors are already
specified in the default configuration: 

[source,yaml]
------------------------------------------------
processors:
- add_cloud_metadata:
- add_host_metadata:
------------------------------------------------

This metadata allows correlation of metrics with the hosts, Kubernetes pods,
Docker containers, and cloud-provider infrastructure metadata and with other
pieces of observability puzzle, such as application performance monitoring data
and logs.

[discrete]
==== Step 10: Deploy {metricbeat} as a DaemonSet on Kubernetes

To deploy {metricbeat} to Kubernetes, run:

[source,shell]
------------------------------------------------
kubectl create -f metricbeat-kubernetes.yaml
------------------------------------------------

To check the status, run:

[source,shell]
------------------------------------------------
$ kubectl --namespace=kube-system  get ds/metricbeat

NAME       DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE-SELECTOR   AGE
metricbeat   32        32        0         32           0           <none>          1m
------------------------------------------------

Metrics should start flowing to {es}.

//REVIEWERS: Can we add some guidance here for what to do when this doesn't
//happen? How do users start to troubleshoot Beats running on k8s? Same comment
//applies to log monitoring.

[discrete]
==== Red Hat OpenShift configuration

If you're using Red Hat OpenShift, you need to specify additional settings in
the manifest file and enable the container to run as privileged.

// Begin collapsed section

[%collapsible]
.Click to see more
====
. Modify the `DaemonSet` container spec in the manifest file:
+
[source,yaml]
-----
  securityContext:
    runAsUser: 0
    privileged: true
-----

. In the manifest file, edit the metricbeat-daemonset-modules ConfigMap, and
specify the following settings under `kubernetes.yml` in the data section:
+
[source,yaml]
-----
kubernetes.yml: |-
    - module: kubernetes
      metricsets:
        - node
        - system
        - pod
        - container
        - volume
      period: 10s
      host: ${NODE_NAME}
      hosts: ["https://${NODE_NAME}:10250"]
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      ssl.certificate_authorities:
        - /path/to/kubelet-service-ca.crt
-----
+
[NOTE]
=========================
`kubelet-service-ca.crt` can be any CA bundle that contains the issuer of
the certificate used in the Kubelet API. According to each specific installation
of Openshift this can be found either in secrets or in configmaps. In some
installations it can be available as part of the service account secret, in
`/var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt`. If you're using
the
https://github.com/openshift/installer/blob/master/docs/user/gcp/install.md[Openshift
installer] for GCP then the following configmap can be mounted in {metricbeat}
pod and use `ca-bundle.crt` in `ssl.certificate_authorities`:

[source,yaml]
-----
 Name:         kubelet-serving-ca
 Namespace:    openshift-kube-apiserver
 Labels:       <none>
 Annotations:  <none>

 Data
 ====
 ca-bundle.crt:
-----
=========================

. Under the `metricbeat` ClusterRole, add the following resources:
+
[source,yaml]
-----
- nodes/metrics
- nodes/stats
-----

. Grant the `metricbeat` service account access to the privileged SCC:
+
[source,shell]
-----
oc adm policy add-scc-to-user privileged system:serviceaccount:kube-system:filebeat
-----
+
This command enables the container to be privileged as an administrator for
OpenShift.

. Override the default node selector for the `kube-system` namespace (or your
custom namespace) to allow for scheduling on any node:
+
[source,shell]
----
oc patch namespace kube-system -p \
'{"metadata": {"annotations": {"openshift.io/node-selector": ""}}}'
----
+
This command sets the node selector for the project to an empty string. If you
don't run this command, the default node selector will skip master nodes.

====
// End collapsed section

[discrete]
=== View performance and health metrics

To view the performance and health metrics collected by {metricbeat}, open
{kib} and go to **{observability} > Metrics**.

On the **Inventory** page, you can switch between different views to see an
overview of the containers and pods running on Kubernetes:

[role="screenshot"]
image::images/metrics-inventory.png[Inventory page that shows Kubernetes pods]

On the **Metrics Explorer** page, you can group and analyze metrics for the
resources that you are monitoring. 

[role="screenshot"]
image::images/metrics-explorer.png[Metrics dashboard that shows CPU usage for Kubernetes pods]

Notice how everywhere you go in {kib}, there is a search bar that allows you to,
you know, search for things. It’s a great way to filter views and zoom into
things when you're looking for that needle in a haystack.

[discrete]
==== Out-of-the-box {kib} dashboards

{metricbeat} ships with a variety of pre-built {kib} dashboards that you can
use to visualize metrics about your Kubernetes environment. If these dashboards
are not already loaded into {kib}, you must run the {metricbeat} setup job. 

TIP: To run the setup job, install {metricbeat} on any system that can connect to
the {stack}, enable the modules for the metricsets you want to monitor, then run
the `setup` command. To learn how, see the
{metricbeat-ref}/metricbeat-installation-configuration.html[{metricbeat} quick start].

On the Kubernetes overview dashboard, you can see an overview of all the nodes,
deployments, and pods running on your Kubernetes cluster:

[role="screenshot"]
image::images/k8s-overview.png[Kubernetes overview dashboard]

You can use these dashboards as they are, or as a starting point for custom
dashboards tailored to your needs.
