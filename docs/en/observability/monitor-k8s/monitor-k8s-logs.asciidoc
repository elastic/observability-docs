[discrete]
[[monitor-kubernetes-logs]]
== Part 1: Monitor logs

Collecting and analyzing logs of both Kubernetes Core components and various
applications running on top of Kubernetes is a powerful tool for Kubernetes
observability. Containers running within Kubernetes pods publish logs to stdout
or stderr. These logs are written to a location known to Kubelet.

To collect pod logs, all you need is {filebeat} running as a DaemonSet
in your Kubernetes cluster. You configure {filebeat} to communicate with the
Kubernetes API server, get the list of pods running on the current host, and
collect the logs the pods are producing. Those logs are annotated with all the
relevant Kubernetes metadata, such as pod ID, container name, container labels
and annotations, and so on.

[discrete]
=== Deploy {filebeat} to collect logs

To start collecting logs, deploy and run an instance of {filebeat} on each
Kubernetes host. {filebeat} communicates with the Kubernetes API server to
retrieve information about the pods running on the host and all the metadata
annotations.

To deploy {filebeat} to your Kubernetes cluster:

[discrete]
==== Step 1: Download the {filebeat} deployment manifest

To make deployment easier, Elastic provides a YAML file that defines all the
required deployment settings. In many cases, you can change the connection
details and deploy with default settings to get started quickly.

["source", "sh", subs="attributes"]
----
curl -L -O https://raw.githubusercontent.com/elastic/beats/{branch}/deploy/kubernetes/filebeat-kubernetes.yaml
----

[discrete]
==== Step 2: Set the connection information for {es}

By default {filebeat} sends events to an existing {es} deployment on `elasticsearch:9200`, if present.
To specify a different destination, change the following settings in the
`filebeat-kubernetes.yaml` file:

[source,yaml]
----
env:
- name: ELASTICSEARCH_HOST
  value: elasticsearch
- name: ELASTICSEARCH_PORT
  value: "9200"
- name: ELASTICSEARCH_USERNAME
  value: elastic <1>
- name: ELASTICSEARCH_PASSWORD
  value: changeme
- name: ELASTIC_CLOUD_ID <2>
  value:
- name: ELASTIC_CLOUD_AUTH <2>
  value:
----
<1> This user must have the privileges required to publish events to {es}. For
more information, see {filebeat-ref}/feature-roles.html[Grant users access to secured resources].
<2> Use the cloud settings if you're sending data to {ess} on {ecloud}.

To avoid exposing sensitive data, you can base64 encode the string, then store it
in a Kubernetes secret. For example:

["source", "sh", subs="attributes"]
------------------------------------------------
$ echo -n 'changeme' | base64
Y2hhbmdlbWU=
$ kubectl create secret generic es-secret --from-literal=password='Y2hhbmdlbWU=' --namespace=kube-system <1>
------------------------------------------------
<1> Create the secret in the namespace where you will deploy {filebeat}.

To use the secret, change the `env` setting in the manifest file:

[source,yaml]
------------------------------------------------
env:
- name: ELASTICSEARCH_PASSWORD
  valueFrom:
    secretKeyRef:
      name: es-secret
      key: password
------------------------------------------------

[discrete]
==== Step 3: Collect container logs

To collect container logs, each {filebeat} instance needs access to the local
log's path, which is actually a log directory mounted from the host. The
default deployment manifest already contains the configuration to do this:

[source,yaml]
------------------------------------------------
filebeat.inputs:
- type: container
  paths:
    - /var/log/containers/*.log
------------------------------------------------

With this configuration, {filebeat} can collect logs from all the files that
exist under the `/var/log/containers/` directory.

This configuration assumes you know what kinds of components are running in a
pod and where the container logs are stored. Later you'll learn how to use
autodiscovery to <<autodiscover-containers, automatically discover containers>>.

[discrete]
==== Step 4: Add metadata to events

{filebeat} provides processors that you can use in your configuration to enrich
events with metadata coming from Docker, Kubernetes, hosts, and cloud providers.

The `add_kubernetes_metadata` processor is already specified in the default
configuration. This processor adds Kubernetes and container-related metadata to
the logs:

[source,yaml]
------------------------------------------------
filebeat.inputs:
- type: container
  paths:
    - /var/log/containers/*.log
  processors:
    - add_kubernetes_metadata:
        host: ${NODE_NAME}
        matchers:
        - logs_path:
            logs_path: "/var/log/containers/"
------------------------------------------------

[discrete]
[[autodiscover-containers]]
==== Step 5: Automatically discover container logs (use autodiscovery)

In the previous steps, you learned how to collect container logs and enrich them
with metadata. However you can take it further by leveraging the autodiscovery
mechanism in {filebeat}. With autodiscovery, {filebeat} can automatically
discover what kind of components are running in a pod and apply the logging
modules needed to capture logs for those components.

NOTE: If you decide to use autodiscovery, make sure you remove or comment
out the `filebeat.inputs` configuration.

To configure autodiscovery, you can use static templates. For example, the
template in this example configures {filebeat} to collect NGINX logs from any
pod labeled as `app: nginx`.

[source,yaml]
------------------------------------------------
filebeat.autodiscover:
  providers:
    - type: kubernetes
      node: ${NODE_NAME}
      templates:
        - condition:
            equals:
              kubernetes.labels.app: "nginx"
          config:
            - module: nginx
              access:
                input:
                  type: container
                  stream: stdout
                  paths:
                    - /var/log/containers/*${data.kubernetes.container.id}.log
              error:
                input:
                  type: container
                  stream: stderr
                  paths:
                    - /var/log/containers/*${data.kubernetes.container.id}.log

------------------------------------------------

This is good, but requires advanced knowledge of the workloads running in
Kubernetes. Each time you want to monitor something new, you'll need to
re-configure and restart {filebeat}. To avoid this, you can use hints-based
autodiscovery:

[source,yaml]
------------------------------------------------
filebeat.autodiscover:
  providers:
    - type: kubernetes
      node: ${NODE_NAME}
      hints.enabled: true
      hints.default_config:
        type: container
        paths:
          - /var/log/containers/*${data.kubernetes.container.id}.log
------------------------------------------------

Then annotate the pods accordingly:

[source,yaml]
------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: nginx-autodiscover
  annotations:
    co.elastic.logs/module: nginx
    co.elastic.logs/fileset.stdout: access
    co.elastic.logs/fileset.stderr: error
------------------------------------------------

With this setup, {filebeat} identifies the NGINX app and starts collecting its
logs by using the `nginx` module.

[discrete]
==== Step 6: (optional) Drop unwanted events

You can enrich your configuration with additional processors to drop unwanted
events. For example:

[source,yaml]
------------------------------------------------
processors:
- drop_event:
      when:
        - equals:
              kubernetes.container.name: "metricbeat"
------------------------------------------------

[discrete]
==== Step 7: Enrich events with cloud metadata and host metadata

You can also enrich events with cloud and host metadata by specifying the
`add_cloud_metadata` and `add_host_metadata` processors. These processors are
already specified in the default configuration:

[source,yaml]
------------------------------------------------
processors:
- add_cloud_metadata:
- add_host_metadata:
------------------------------------------------

[discrete]
==== Step 8: Deploy {filebeat} as a DaemonSet on Kubernetes

. If you're running {filebeat} on master nodes, check to see if the nodes use
https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/[taints].
Taints limit the workloads that can run on master nodes. If necessary, update
the DaemonSet spec to include tolerations:
+
[source,yaml]
------------------------------------------------
spec:
  tolerations:
  - key: node-role.kubernetes.io/master
    effect: NoSchedule
------------------------------------------------

. Deploy {filebeat} to Kubernetes:
+
["source", "sh", subs="attributes"]
------------------------------------------------
kubectl create -f filebeat-kubernetes.yaml
------------------------------------------------
+
To check the status, run:
+
["source", "sh", subs="attributes"]
------------------------------------------------
$ kubectl --namespace=kube-system get ds/filebeat

NAME       DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE-SELECTOR   AGE
filebeat   32        32        0         32           0           <none>          1m
------------------------------------------------
+
Log events should start flowing to {es}.

[discrete]
==== Red Hat OpenShift configuration

If you're using Red Hat OpenShift, you need to specify additional settings in
the manifest file and enable the container to run as privileged.

// Begin collapsed section

[%collapsible]
.Click to see more
====
. Modify the `DaemonSet` container spec in the manifest file:
+
[source,yaml]
-----
  securityContext:
    runAsUser: 0
    privileged: true
-----

. Grant the `filebeat` service account access to the privileged SCC:
+
[source,shell]
-----
oc adm policy add-scc-to-user privileged system:serviceaccount:kube-system:filebeat
-----
+
This command enables the container to be privileged as an administrator for
OpenShift.

. Override the default node selector for the `kube-system` namespace (or your
custom namespace) to allow for scheduling on any node:
+
[source,shell]
----
oc patch namespace kube-system -p \
'{"metadata": {"annotations": {"openshift.io/node-selector": ""}}}'
----
+
This command sets the node selector for the project to an empty string. If you
don't run this command, the default node selector will skip master nodes.

====
// End collapsed section

[discrete]
=== View logs in {kib}

To view the log data collected by {filebeat}, open {kib} and go to
**{observability} > Logs**.

The https://www.elastic.co/log-monitoring[{logs-app}] in {kib} allows you to
search, filter, and tail all the logs collected into the {stack}. Instead of
having to ssh into different servers and tail individual files, all the logs are
available in one tool under the {logs-app}.

[role="screenshot"]
image::images/log-stream.png[{logs-app} streaming messages collected by {filebeat}]

Explore the {logs-app}:

* Enter a keyword or text string in the search field to filter logs. 
* Use the time picker or timeline view on the side to move forward and back in
time.
* Click **Stream live** to watch the logs update in front of you `tail -f`
style.
* Place your cursor over a log message to highlight it, then use the context
menu to view details or view the log message in context. 


[discrete]
==== Out-of-the-box {kib} dashboards

{filebeat} ships with a variety of pre-built {kib} dashboards that you can
use to visualize logs from Kubernetes Core components and applications running
on top of Kubernetes. If these dashboards are not already loaded into {kib}, you
must run the {filebeat} setup job. 

TIP: To run the setup job, install {filebeat} on any system that can connect to
the {stack}, enable the modules for the datasets you want to monitor, then run
the `setup` command. To learn how, see the
{filebeat-ref}/filebeat-installation-configuration.html[{filebeat} quick start].


After loading the dashboards, navigate to **{kib} > Dashboards**
and search for the services you want to monitor, like MySQL or NGINX.

//TODO: Add screen capture here

Notice that modules capture more than logs. You can also use them to capture
metrics. 
