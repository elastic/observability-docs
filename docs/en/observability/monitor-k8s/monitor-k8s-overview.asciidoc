[discrete]
[[kubernetes-monitoring-architecture]]
== Monitoring architecture

The {stack} provides the following components for monitoring Kubernetes:

1. {agent} is a single, unified way to add monitoring for data like logs and metrics to your host.

2. The Elastic Kubernetes integration, in tandem with {agent}, collects logs and metrics from Kubernetes clusters.

3. APM (described later) to monitor, detect, and diagnose complex application
performance issues.

4. {es} for storing and searching your data.

5. {observability} apps in {kib} for visualizing and managing your observability
data.

//update image to show agents instead of beats
//image::images/k8s-monitoring-architecture.png[Kubernetes monitoring architecture]


{agent} is deployed to Kubernetes as a DaemonSet to ensure an instance is running on each node of the cluster.
It collects logs and metrics from pods, containers, and applications running on Kubernetes.

//rewrite to be agent specific. Focus on logs and metrics instead of filebeat and metricbeat

////
{filebeat} communicates with the Kubernetes API server to retrieve information
about the pods running on the host, all the metadata annotations, and the
location of the log files.

When autodiscovery is configured, {filebeat} automatically discovers what
kind of components are running in a pod and applies the logging modules needed
to capture logs for those components.

**{metricbeat}**: Collects and preprocesses system and service metrics, such as
information about running processes, as well as CPU, memory, disk, and network
utilization numbers.

Because {metricbeat} runs on each node, it can collect metrics from the Kubelet
API. These metrics provide important information about the state of the
Kubernetes nodes, pods, containers, and other resources.

For cluster-wide metrics, {metricbeat} accesses the `kube-state-metrics`
service directly or gets metrics scraped by Prometheus.

When hints-based autodiscovery is configured, {metricbeat} looks for hints
in Kubernetes pod annotations or Docker labels and launches the proper
configuration to collect application metrics.

**Other {beats} (not shown)**: Collect and process other types of data, such as
Uptime data and network traffic.
////

[discrete]
[[beats-metadata]]
=== Metadata

{agent} provides processors for adding metadata to events. The
metadata is valuable for grouping and exploring related data. For example, when
you're analyzing container logs, you want to know the host and container name,
and you want to be able to correlate logs, metrics, and traces.

The default deployments include processors, when needed, for enriching events
with cloud, Kubernetes, and host metadata.

image::images/metadata-processors.png[Metadata processors for cloud, Kubernetes, and host metadata]

For more on these processors, refer to the {fleet-guide}/add-cloud-metadata-processor.html[`add_cloud_metadata`], {fleet-guide}/add_kubernetes_metadata-processor.html[`add_kubernetes_metadata`], and {fleet-guide}/add_host_metadata-processor.html[`add_host_metadata`] documentation.

Now that you have a basic understanding of the monitoring architecture, let's
learn how to deploy monitoring to your Kubernetes environment.

[discrete]
== Before you begin

Before you can monitor Kubernetes, you need the following:

* {es} for storing and searching your observability data and {kib} for visualizing and managing it.
* If you want to collect Kubernetes state metrics, you need to deploy `kube-state-metrics`.
Refer to the Kubernetes https://github.com/kubernetes/kube-state-metrics#kubernetes-deployment[docs] for deployment instructions.