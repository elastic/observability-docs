[[apm-custom-filter]]
= Custom filters

status_badge::[cloud_serverless, unavailable]

include::{observability-docs-root}/docs/en/observability/apm/security/data-security/index.asciidoc[tag=custom-filters]

[discrete]
[[apm-filters-ingest-pipeline]]
== Create an ingest pipeline filter

Ingest node pipelines specify a series of processors that transform data in a specific way.
Transformation happens prior to indexing--inflicting no performance overhead on the monitored application.
Pipelines are a flexible and easy way to filter or obfuscate Elastic APM data.

[discrete]
[[apm-filters-ingest-pipeline-tutorial]]
=== Tutorial: redact sensitive information

Say you decide to <<apm-filters-http-body,capture HTTP request bodies>>
but quickly notice that sensitive information is being collected in the
`http.request.body.original` field:

[source,json]
----
{
  "email": "test@abc.com",
  "password": "hunter2"
}
----

**Create a pipeline**

To obfuscate the passwords stored in the request body,
you can use a series of {ref}/processors.html[ingest processors].
To start, create a pipeline with a simple description and an empty array of processors:

[source,json]
----
{
  "pipeline": {
    "description": "redact http.request.body.original.password",
    "processors": [] <1>
  }
}
----
<1> The processors defined below will go in this array

**Add a JSON processor**

Add your first processor to the processors array.
Because the agent captures the request body as a string, use the
{ref}/json-processor.html[JSON processor] to convert the original field value into a structured JSON object.
Save this JSON object in a new field:

[source,json]
----
{
  "json": {
    "field": "http.request.body.original",
    "target_field": "http.request.body.original_json",
    "ignore_failure": true
  }
}
----

**Add a set processor**

If `body.original_json` is not `null`, i.e., it exists, we'll redact the `password` with the {ref}/set-processor.html[set processor],
by setting the value of `body.original_json.password` to `"redacted"`:

[source,json]
----
{
  "set": {
    "field": "http.request.body.original_json.password",
    "value": "redacted",
    "if": "ctx?.http?.request?.body?.original_json != null"
  }
}
----

**Add a convert processor**

Use the {ref}/convert-processor.html[convert processor] to convert the JSON value of `body.original_json` to a string and set it as the `body.original` value:

[source,json]
----
{
  "convert": {
    "field": "http.request.body.original_json",
    "target_field": "http.request.body.original",
    "type": "string",
    "if": "ctx?.http?.request?.body?.original_json != null",
    "ignore_failure": true
  }
}
----

**Add a remove processor**

Finally, use the {ref}/remove-processor.html[remove processor] to remove the `body.original_json` field:

[source,json]
----
{
  "remove": {
    "field": "http.request.body.original",
    "if": "ctx?.http?.request?.body?.original_json != null",
    "ignore_failure": true
  }
}
----

**Register the pipeline**

Now we'll put it all together.
Use the {ref}/put-pipeline-api.html[create or update pipeline API] to register the new pipeline in {es}.
Name the pipeline `apm_redacted_body_password`:

[source,console]
----
PUT _ingest/pipeline/apm_redacted_body_password
{
  "description": "redact http.request.body.original.password",
  "processors": [
    {
      "json": {
        "field": "http.request.body.original",
        "target_field": "http.request.body.original_json",
        "ignore_failure": true
      }
    },
    {
      "set": {
        "field": "http.request.body.original_json.password",
        "value": "redacted",
        "if": "ctx?.http?.request?.body?.original_json != null"
      }
    },
    {
      "convert": {
        "field": "http.request.body.original_json",
        "target_field": "http.request.body.original",
        "type": "string",
        "if": "ctx?.http?.request?.body?.original_json != null",
        "ignore_failure": true
      }
    },
    {
      "remove": {
        "field": "http.request.body.original_json",
        "if": "ctx?.http?.request?.body?.original_json != null",
        "ignore_failure": true
      }
    }
  ]
}
----

**Test the pipeline**

Prior to enabling this new pipeline, you can test it with the {ref}/simulate-pipeline-api.html[simulate pipeline API].
This API allows you to run multiple documents through a pipeline to ensure it is working correctly.

The request below simulates running three different documents through the pipeline:

[source,console]
----
POST _ingest/pipeline/apm_redacted_body_password/_simulate
{
  "docs": [
    {
      "_source": { <1>
        "http": {
          "request": {
            "body": {
              "original": """{"email": "test@abc.com", "password": "hunter2"}"""
            }
          }
        }
      }
    },
    {
      "_source": { <2>
        "some-other-field": true
      }
    },
    {
      "_source": { <3>
        "http": {
          "request": {
            "body": {
              "original": """["invalid json" """
            }
          }
        }
      }
    }
  ]
}
----
<1> This document features the same sensitive data from the original example above
<2> This document only contains an unrelated field
<3> This document contains invalid JSON

The API response should be similar to this:

[source,json]
----
{
  "docs" : [
    {
      "doc" : {
        "_source" : {
          "http" : {
            "request" : {
              "body" : {
                "original" : {
                  "password" : "redacted",
                  "email" : "test@abc.com"
                }
              }
            }
          }
        }
      }
    },
    {
      "doc" : {
        "_source" : {
          "nobody" : true
        }
      }
    },
    {
      "doc" : {
        "_source" : {
          "http" : {
            "request" : {
              "body" : {
                "original" : """["invalid json" """
              }
            }
          }
        }
      }
    }
  ]
}
----

As expected, only the first simulated document has a redacted password field.
All other documents are unaffected.

**Create an `@custom` pipeline**

The final step in this process is to call the newly created `apm_redacted_body_password` pipeline
from the `@custom` pipeline of the data stream you wish to edit.

include::{observability-docs-root}/docs/en/observability/apm/manage-storage/ingest-pipelines.asciidoc[tag=ingest-pipeline-naming]

Use the {ref}/put-pipeline-api.html[create or update pipeline API] to register the new pipeline in {es}.
Name the pipeline `traces-apm@custom`:

[source,console]
----
PUT _ingest/pipeline/traces-apm@custom
{
  "processors": [
    {
      "pipeline": {
        "name": "apm_redacted_body_password" <1>
      }
    }
  ]
}
----
<1> The name of the pipeline we previously created

TIP: If you prefer using a GUI, you can instead use the **Ingest Pipelines** page in {kib}.
To open **Ingest Pipelines**, find **Stack Management** in the main menu or use the {kibana-ref}/introduction.html#kibana-navigation-search[global search field].
Click **Create pipeline** and use the same naming convention explained previously to ensure your new pipeline matches the correct APM data stream.

That's it! Passwords will now be redacted from your APM HTTP body data.

To learn more about ingest pipelines, see <<apm-custom-index-template>>.

[discrete]
[[apm-filters-in-agent]]
== APM agent filters

Some APM agents offer a way to manipulate or drop APM events _before_ they are sent to the APM Server.
Please see the relevant agent's documentation for more information and examples:

// * Go: {apm-go-ref-v}/[]
// * Java: {apm-java-ref-v}/[]
* .NET: {apm-dotnet-ref-v}/public-api.html#filter-api[Filter API].
* Node.js: {apm-node-ref-v}/agent-api.html#apm-add-filter[`addFilter()`].
// * PHP: {apm-php-ref-v}[]
* Python: {apm-py-ref-v}/sanitizing-data.html[custom processors].
* Ruby: {apm-ruby-ref-v}/api.html#api-agent-add-filter[`add_filter()`].
