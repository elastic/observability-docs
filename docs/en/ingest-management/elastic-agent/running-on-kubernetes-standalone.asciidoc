[[running-on-kubernetes-standalone]]
= Run {agent} Standalone on Kubernetes

include::{fleet-repo-dir}/standalone-note.asciidoc[]

:manifest: https://raw.githubusercontent.com/elastic/elastic-agent/{branch}/deploy/kubernetes/elastic-agent-standalone-kubernetes.yaml
:show-condition: enabled

== What you need

- https://kubernetes.io/docs/tasks/tools/[kubectl installed].

- {es} for storing and searching your data, and {kib} for visualizing and managing it.
+
--
include::{observability-docs-root}/docs/en/shared/spin-up-the-stack/widget.asciidoc[]
--

- `kube-state-metrics`.
+
include::run-container-common/deploy-kube-state-metrics.asciidoc[]

[discrete]
== Step 1: Download the {agent} manifest


include::run-container-common/download-elastic-agent.asciidoc[]


[discrete]
== Step 2: Connect to the {stack}

Set the {es} settings before deploying the manifest:

[source,yaml]
------------------------------------------------
- name: ES_USERNAME
  value: "elastic" <1>
- name: ES_PASSWORD
  value: "passpassMyStr0ngP@ss" <2>
- name: ES_HOST
  value: "https://somesuperhostiduuid.europe-west1.gcp.cloud.es.io:9243" <3>
------------------------------------------------

<1> The basic authentication username used to connect to {es}.
<2> The basic authentication password used to connect to {kib}.
<3> The {es} host to communicate with.

Refer to <<agent-environment-variables>> for all available options.


[discrete]
== Step 3: Configure tolerations
include::run-container-common/agent-tolerations.asciidoc[]

:manifest: elastic-agent-standalone-kubernetes.yaml
[discrete]
== Step 4: Deploy the {agent}
include::run-container-common/deploy-elastic-agent.asciidoc[]

[discrete]
== Step 5: View your data in {kib}


. Launch {kib}:
+
--
include::{observability-docs-root}/docs/en/shared/open-kibana/widget.asciidoc[]
--

. You can see data flowing in by going to *Analytics -> Discover* and selecting the index `metrics-*`, or even more specific, `metrics-kubernetes.*`. If you can't see these indexes, {kibana-ref}/data-views.html[create a data view] for them.

. You can see predefined dashboards by selecting *Analytics->Dashboard*, or by <<view-integration-assets,installing assets through an integration>>.


[discrete]
= Red Hat OpenShift configuration

If you are using Red Hat OpenShift, you need to specify additional settings in the manifest file and enable the container to run as privileged.

. In the manifest file, modify the `agent-node-datastreams` ConfigMap and adjust inputs:
+
--
* `kubernetes-cluster-metrics` input:
** If `https` is used to access `kube-state-metrics`, add the following settings to all `kubernetes.state_*` datasets:
+
[source,yaml]
------------------------------------------------
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  ssl.certificate_authorities:
    - /var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt
------------------------------------------------
* `kubernetes-node-metrics` input:
** Change the `kubernetes.controllermanager` data stream condition to:
+
[source,yaml]
------------------------------------------------
condition: ${kubernetes.labels.app} == 'kube-controller-manager'
------------------------------------------------
** Change the `kubernetes.scheduler` data stream condition to:
+
[source,yaml]
------------------------------------------------
condition: ${kubernetes.labels.app} == 'openshift-kube-scheduler'
------------------------------------------------
** The `kubernetes.proxy` data stream configuration should look like:
+
[source,yaml]
------------------------------------------------
- data_stream:
    dataset: kubernetes.proxy
    type: metrics
  metricsets:
    - proxy
  hosts:
    - 'localhost:29101'
  period: 10s
------------------------------------------------
** Add the following settings to all data streams that connect to `https://${env.NODE_NAME}:10250`:
+
[source,yaml]
------------------------------------------------
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  ssl.certificate_authorities:
    - /path/to/ca-bundle.crt
------------------------------------------------
NOTE: `ca-bundle.crt` can be any CA bundle that contains the issuer of the certificate used in the Kubelet API.
According to each specific installation of OpenShift this can be found either in `secrets` or in `configmaps`.
In some installations it can be available as part of the service account secret, in
`/var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt`.
When using the https://github.com/openshift/installer/blob/master/docs/user/gcp/install.md[OpenShift installer]
for GCP, mount the following `configmap` in the elastic-agent pod and use `ca-bundle.crt`
in `ssl.certificate_authorities`:
+
[source,shell]
-----
Name:         kubelet-serving-ca
Namespace:    openshift-kube-apiserver
Labels:       <none>
Annotations:  <none>

Data
====
ca-bundle.crt:
-----
--
. Grant the `elastic-agent` service account access to the privileged SCC:
+
[source,shell]
-----
oc adm policy add-scc-to-user privileged system:serviceaccount:kube-system:elastic-agent
-----
+
This command enables the container to be privileged as an administrator for
OpenShift.

. If the namespace where elastic-agent is running has the `"openshift.io/node-selector"` annotation set, elastic-agent
might not run on all nodes. In this case consider overriding the node selector for the namespace to allow scheduling
on any node:
+
[source,shell]
----
oc patch namespace kube-system -p \
'{"metadata": {"annotations": {"openshift.io/node-selector": ""}}}'
----
+
This command sets the node selector for the project to an empty string.


[discrete]
== Autodiscover targeted Pods

Refer to <<elastic-agent-kubernetes-autodiscovery>> for more information.


:manifest:
:show-condition: