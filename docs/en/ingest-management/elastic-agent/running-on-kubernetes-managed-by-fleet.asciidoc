[[running-on-kubernetes-managed-by-fleet]]
= Run {agent} on Kubernetes managed by {fleet}

Use {agent} https://www.docker.elastic.co/r/beats/elastic-agent[Docker images] on Kubernetes to
retrieve cluster metrics.

TIP: Running {ecloud} on Kubernetes? Refer to {eck-ref}/k8s-elastic-agent-fleet.html[Run {elastic-agent} on ECK].

ifeval::["{release-state}"=="unreleased"]

However, version {version} of {agent} has not yet been
released, so no Docker image is currently available for this version.

endif::[]


[discrete]
== Kubernetes deploy manifests

With {fleet}, each agent enrolls in a policy defined in {kib} and stored in
{es}. The policy specifies how to collect observability data from the services
to be monitored. The {agent} connects to a trusted {fleet-server} instance
to retrieve the policy and report agent events.

We recommend using {fleet} management because it makes the management and
upgrade of agents considerably easier.

On Kubernetes, deploy {agent} as a https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/[DaemonSet]
to ensure that there is a running instance on each node of the cluster.
These instances are used to retrieve metrics from the host, such as system metrics, container stats,
and metrics from all the services running on top of Kubernetes.

In addition, one of the Pods in the DaemonSet will constantly hold a _leader lock_ which makes it responsible for
handling cluster-wide monitoring.
Find more information about leader election configuration options at <<kubernetes_leaderelection-provider, leader election provider>>.
This instance is used to retrieve metrics that are unique for the whole
cluster, such as Kubernetes events or
https://github.com/kubernetes/kube-state-metrics[kube-state-metrics].


Everything is deployed under the `kube-system` namespace by default. To change
the namespace, modify the manifest file.

To download the manifest file, run:

["source", "sh", subs="attributes"]
------------------------------------------------
curl -L -O https://raw.githubusercontent.com/elastic/elastic-agent/{branch}/deploy/kubernetes/elastic-agent-managed-kubernetes.yaml
------------------------------------------------

[discrete]
== Settings

{agent} is enrolled to a running {fleet-server} using `FLEET_URL` parameter.
The `FLEET_ENROLLMENT_TOKEN` parameter is used to connect {agent} to a
specific {agent} policy.
To learn how to get an enrollment token from {fleet}, see <<fleet-enrollment-tokens>>.

To specify different destination/credentials,
change the following parameters in the manifest file:

[source,yaml]
------------------------------------------------
- name: FLEET_URL
  value: "https://fleet-server_url:port"
- name: FLEET_ENROLLMENT_TOKEN
  value: "token"
- name: FLEET_SERVER_POLICY_ID
  value: "fleet-server-policy" <1>
- name: KIBANA_HOST
  value: ""
- name: KIBANA_FLEET_USERNAME
  value: ""
- name: KIBANA_FLEET_PASSWORD
  value: ""
------------------------------------------------
<1> To learn how to create a policy, refer <<create-a-policy-no-ui>>.


// Begin collapsed section
[%collapsible]
.Configuration details
====
****

[cols="2*<a"]
|===
| Settings | Description

include::configuration/env/shared-env.asciidoc[tag=fleet-url]

include::configuration/env/shared-env.asciidoc[tag=fleet-enrollment-token]

include::configuration/env/shared-env.asciidoc[tag=fleet-server-policy-id]

include::configuration/env/shared-env.asciidoc[tag=kibana-host]

include::configuration/env/shared-env.asciidoc[tag=kibana-fleet-username]

include::configuration/env/shared-env.asciidoc[tag=kibana-fleet-password]
|===

Refer to <<agent-environment-variables>> for all available options.

****
====

[discrete]
=== Run {agent} on master nodes

Kubernetes master nodes can use https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/[taints]
to limit the workloads that can run on them. The manifest for managed {agent} defines
tolerations to run on master nodes. Agents running on master nodes collect metrics from the control plane
components (scheduler, controller manager) of Kubernetes.
To disable {agent} from running on master nodes, remove the following part of the Daemonset spec:

[source,yaml]
------------------------------------------------
spec:
 tolerations:
 - key: node-role.kubernetes.io/master
   effect: NoSchedule
------------------------------------------------


[discrete]
== Deploy

If planning to deploy `state_*` datasets of Kubernetes package,
https://github.com/kubernetes/kube-state-metrics#usage[kube-state-metrics] needs to be already deployed
in the cluster. If `kube-state-metrics` is not already running, deploy it now (see the
https://github.com/kubernetes/kube-state-metrics#kubernetes-deployment[Kubernetes
deployment] docs).

To deploy {agent} on Kubernetes, run:

["source", "sh", subs="attributes"]
------------------------------------------------
kubectl create -f elastic-agent-managed-kubernetes.yaml
------------------------------------------------

To check the status, run:

["source", "sh", subs="attributes"]
------------------------------------------------
$ kubectl get pod -n kube-system -l app=elastic-agent

NAME                  READY   STATUS    RESTARTS   AGE
elastic-agent-hrjbg   1/1     Running   0          12m
elastic-agent-olpsd   1/1     Running   0          12m
------------------------------------------------

NOTE: You might need to adjust https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/[resource limits] of the elastic-agent container
in the `elastic-agent-managed-kubernetes.yaml` manifest. Container resource usage depends on the number of datastreams
and the environment size.

{agent}s should be enrolled to {fleet} and users should be able to deploy the Kubernetes package accordingly.
This can be confirmed in {kib} under {fleet}  / Agents section.


[discrete]
== Deploying {agent} to collect cluster-level metrics in large clusters

The size and the number of nodes in a Kubernetes cluster can be fairly large at times,
and in such cases the Pod that will be collecting cluster level metrics might face performance
issues due to resources limitations. In this case users might consider to avoid using the
leader election strategy and instead run a dedicated, standalone {agent} instance using
a Deployment in addition to the DaemonSet.

[discrete]
== Deploying {agent} to managed Kubernetes environment

On managed Kubernetes solutions, such as AKS, GKE or EKS, {agent} has no access to collect metrics from the https://kubernetes.io/docs/concepts/overview/components/#control-plane-components[Kubernetes control plane]
components, like `kube-scheduler` and `kube-controller-manager`, that are scheduled on Kubernetes master nodes.

Audit logs are available only on Kubernetes master nodes as well and hence cannot be collected by {agent}.
