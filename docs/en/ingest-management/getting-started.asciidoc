[[fleet-quick-start]]
[role="xpack"]
= Quick start: Get logs and metrics into the {stack}

beta[]

This guide describes how to:

* Collect logs and metrics from systems and services across your organization
* Send the data to the {stack}
* Explore and visualize the data in real-time

For feedback and questions, please contact us in the {forum}[discuss forum].

[discrete]
[[fleet-prereqs]]
== Prerequisites

Before you begin, please read <<fleet-limitations>>.

You need {es} for storing and searching your data, and {kib} for visualizing and
managing it. You can use our
{ess-product}[hosted {ess}]
on {ecloud} (recommended), or self-manage the {stack} on your own hardware.

Here's what you need for each deployment type:

include::{tab-widgets}/prereq-widget.asciidoc[]

[discrete]
[[set-up-fleet]]
== Step 1: Set up {fleet}

The best way to get logs, metrics, and security data into the {stack} is
by using {fleet} in {kib}.

TIP: Not using {fleet}? Advanced users who want to configure and manage
{agent}s manually can <<run-elastic-agent-standalone,run agents standalone>>.

The first time you use {fleet}, you need to set it up:

. Log in to {kib} and go to **Management > {fleet}**.
+
[role="screenshot"]
image::images/kibana-fleet-start.png[{fleet} in {kib}]

. In {fleet}, click **Settings** and change the defaults, if necessary.
For self-managed installations, set the URLs for {es} and {kib}, including
the http ports, then save your changes.
+
[role="screenshot"]
image::images/kibana-fleet-settings.png[{fleet} settings]

. Enable central management. Click the **Agents** tab and click
**Create user and enable central management**.
+
[role="screenshot"]
image::images/kibana-fleet-enable.png[{fleet} showing prompt to enable central management]

[discrete]
[[add-agent-to-fleet]]
== Step 2: Add an {agent} to {fleet}

include::elastic-agent/elastic-agent.asciidoc[tag=agent-install-intro]

To send logs and metrics to the {stack}:

. On the **Agents** tab in {fleet}, click **Add agent**, and look at the
deployment instructions under **Enroll in {fleet}**.

. As instructed, download and extract the {agent} to your host. To do this
quickly from the command line, run:
+
--
include::elastic-agent/install-elastic-agent.asciidoc[tag=install-elastic-agent]

See the https://www.elastic.co/downloads/elastic-agent[download page] for other
installation options.
--

. Back in {fleet}, under **Choose an agent policy**, notice that the default
policy is selected. The default policy includes a system integration for
collecting logs and metrics from the host system. Use the default policy to get
started quickly.

. Under **Enroll and start the {agent}**, copy the install command if it's
available for your platform, or make a note of the {kib} URL and enrollment
token that was generated by {fleet}.
+
[role="screenshot"]
image::images/kibana-fleet-enroll.png[{fleet} showing agent enrollment page]

. From the agent directory, run the appropriate command to install, enroll, and
start an {agent}. Note that this command installs {agent} files in the locations
described in <<installation-layout>>.
+
--
include::{tab-widgets}/install-widget.asciidoc[]
--
+
Because {agent} is installed as an auto-starting service, it will restart
automatically if the system is rebooted.

. In {fleet}, click **Continue** to go to the **Agents** tab, where you should
see the newly enrolled agent.
+
[role="screenshot"]
image::images/kibana-fleet-agents.png[{fleet} showing enrolled agents]

TIP: If the status hangs at Enrolling, make sure the `elastic-agent` process
is running.

If you run into problems, see <<fleet-troubleshooting>>.

[discrete]
[[view-data]]
== Step 3: Monitor host logs and metrics

Next, view the data sent by {agent}. Right now, {agent} is only sending data
about the host system because you haven't configured the agent to collect data
from other sources yet.

To see host logs and metrics:

. In {fleet}, click the **Data streams** tab.
. In the **Actions** column, navigate to the dashboards corresponding
to the data stream. For example, to see host metrics, select one of the system
datasets:
+
[role="screenshot"]
image::images/kibana-fleet-datastreams.png[{fleet} showing data streams list]
+
Then navigate to the [Metrics System] Host overview dashboard:
+
[role="screenshot"]
image::images/host-metrics.png[Host overview dashboard in {kib}]

[discrete]
[[add-nginx-integration]]
== Step 4: Monitor Nginx logs and metrics
[discrete]

Next, you'll browse a catalog of integrations, then add an Nginx integration to
the default policy used by your agent. You use policies to manage settings
across a group of agents. An agent policy may contain any number of integrations
for collecting observability data from the various services running on your
host.

NOTE: For these steps, we assume that you have `nginx` running on some of your
infrastructure, and want to collect logs and metrics from it.

. In {kib}, go back to **Management > {fleet}**, and click the **Integrations**
tab. Use the search bar to find the Nginx integration.
+
[role="screenshot"]
image::images/kibana-fleet-integrations-nginx.png[{fleet} showing Nginx integration]
. Click the Nginx integration to see more details about it, then click
**Add Nginx**.
+
[role="screenshot"]
image::images/kibana-fleet-integrations-nginx-overview.png[{fleet} showing Nginx integration overview]

. On the **Add Nginx integration** page, select the default policy.
+
In this guide, you add integrations to the default policy created by
{kib}. After you learn the basics, you can create your own policies and assign
them to agents.
+
[role="screenshot"]
image::images/add-integration.png[{fleet} Add Nginx integration page]

. Under **Configure integration**, click the down arrow next to enabled streams
and make sure the **Paths** are correct for your host. Inspect or change other
settings

. When you're done, save and deploy the changes.
+
The newly added Nginx integration should appear under **Integrations** in the
default policy, along with the `system-1` integration that you used earlier to
collect host data.
+
[role="screenshot"]
image::images/kibana-fleet-policies-default-with-nginx.png[{fleet} showing default agent policy with nginx-1 datasource]
+
All {agent}s that use this policy will collect logs and metrics from the
Nginx server and the host.

. To view the data, click the **Data streams** tab.

. In the **Actions** column, navigate to the dashboards corresponding
to the data stream.

//TODO: Add dashboard.

[discrete]
== Data from Splunk (Experimental)

Apache, AWS Cloudtrail, Nginx, and Zeek integrations offer the ability
to seamlessly ingest data from a Splunk Enterprise instance.  Data
will be automatically mapped to the Elastic Common Schema, making it
available for rapid analysis in Elastic solutions, including Security
and Observability.

These integrations work by using the `httpjson` input in {agent} to
run a Splunk search via the Splunk REST API and then extract the raw
event from the results.  The raw event is then processed via the
{agent}.  The Splunk search is customizable and the interval between
searches is customizable.  These integrations only get new data since
the last query, not historical data.

[role="screenshot"]
image::images/elastic-agent-splunk.png[Splunk integration components]

To ingest Nginx data from Splunk the following steps are performed.
The options are the same for Apache, AWS Cloudtrail and Zeek.

. Find the Nginx integration and begin adding it as described in <<<add-nginx-integration>>>.

. Enable "Collect logs from third-party REST API" and disable both "Collect
logs from Nginx instances" and "Collect metrics from Nginx instances".
+
[role="screenshot"]
image::images/kibana-fleet-third-party-rest-api.png[{fleet} showing enabling third-party REST API]

. Enter the required information to connect to the Splunk Enterprise REST API.
+
The URL of the Splunk Enterprise Server must include the scheme (http or https),
the IP address or hostname of the Splunk Enterprise Server, and the the port the
REST API is listening on.
+
The Splunk username and password must be of a user with a role or
capability to use REST API endpoints.  Administrative users have these
permissions by default.
+
SSL Configuration is available under the "Advanced options".  These may be necessary
if Splunk Enterprise server uses self signed certificates.  See
https://www.elastic.co/guide/en/beats/filebeat/current/configuration-ssl.html[SSL Options]
for valid configuration options.
+
[role="screenshot"]
image::images/kibana-fleet-third-party-rest-settings.png[{fleet} showing enabling third-party REST API settings]

. For each type of log file enter the interval and Splunk search string.
+
The interval is expressed as a
https://golang.org/pkg/time/#ParseDuration[Go duration].  The interval
is the time between requests sent to the Splunk Enterprise REST API to
request new information.  Intervals less than one second are not
recommended, Splunk only maintains second accuracy for index time.
The interval should closely match the rate at which data arrives at
the Splunk Enterprise Server.  For example an interval of "5s" for
data that only arrives at the Splunk Enterprise Server every hour will
generate unnecessary load on the Splunk Enterprise Server.
+
The search string is the Splunk search used to uniquely describe the
events that match the type of log file you are trying to configure.
For example, to uniquely describe Nginx access logs "search
sourcetype=nginx:plus:access" might be used.  Note, the search string
must begin with "search" for details refer to the Splunk REST API
manual and the "search/jobs/export" endpoint.
+
Be aware that each time the {agent} connects to the Splunk Enterprise
REST API a Splunk search is performed.  Because of this you want to be
sure your search string is as specific as possible, since this reduces
the load on the Splunk Enterprise Server.
+
Tags may be added in the "Advanced options".  For example, if you'd
like to tag events coming from Splunk with a 'Splunk' tag, you can add
it here.  By default, the forward tag is present to indicate that
events are being forwarded via an intermediary, i.e. Splunk.
+
[role="screenshot"]
image::images/kibana-fleet-third-party-rest-dataset-settings.png[{fleet} showing enabling third-party REST API settings]

. Click Save Integration
. Data and Dashboards will be available just as if you had collected
the data on the nginx host using log files.


[discrete]
=== Considerations / Questions

The time on the host running the agent and the Splunk Enterprise
Server should be synchronized to the same time source, with correct
timezone information.  Failure to do this could result in delays in
transferring data or gaps in the data received.

Does the Splunk data need to be in a specific format or mapped to
Splunk's Common Information Model?  No, because these integrations
take the raw event from Splunk and process that.  There is no
dependency on any Splunk processing.

Are events mapped to Elastic Common Schema (ECS)?  Yes, events from
these integrations go through the exact same processing as if {agent}
had gotten the event from the original source.  So the same level of
mapping to ECS occurs.


[discrete]
== What's next?

* Now that data is streaming into the {stack}, take your investigation to a
deeper level! Use https://www.elastic.co/observability[Elastic {observability}]
to unify your logs, metrics, uptime, and application performance data.

* Want to protect your endpoints from security threats? Try
https://www.elastic.co/security[{elastic-sec}]. Adding endpoint protection is
just another integration that you add to the agent policy!

* Are your eyes bleary from staring at a wall of screens?
{observability-guide}/create-alerts.html[Create alerts] and find out about
problems while sipping your favorite beverage poolside.

* Want Elastic to do the heavy lifting? Use machine learning to
{observability-guide}/inspect-log-anomalies.html[detect anomalies].

* Got everything working like you want it? Roll out your agent policies to
other hosts by deploying {agent}s across your infrastructure!

// Add Javascript and CSS for tabbed panels
include::{tab-widgets}/code.asciidoc[]
