[[add-a-fleet-server]]
= Add a {fleet-server}

To use {fleet} for central management, a <<fleet-server,{fleet-server}>> must
be running and accessible to your hosts. This page describes how to add a
{fleet-server} to an {ecloud} or self-managed deployment.

There are three approaches you can take when deploying {fleet-server}:

* <<deployed-in-cloud>> as part of the hosted {ess}, which is managed by Elastic
* <<deployed-on-prem>>
* <<fleet-server-on-prem-es-cloud>>

Read more about each to choose the best approach for your situation.

[discrete]
[[deployed-in-cloud]]
== Deploy on {ecloud}

// What is it...
To simplify the deployment of {agent}, {fleet-server} can be provisioned and
hosted on {ecloud}. In this case, when the deployment is created,
a highly available set of {fleet-server}s is automatically deployed.

// Benefits
This approach might be right for you if you want to reduce on-prem compute,
and you'd like Elastic to take care of provisioning and life cycle management of your deployment.

// Limitations
This approach might not be right for you if you have restrictions on connectivity to the internet.

// How to
With this approach, you can choose the resources allocated to each {fleet-server}
and whether you want each {fleet-server} to be deployed in multiple availability zones.
Once deployed on {ecloud} as a service, the full life cycle of {fleet-server}
is managed by Elastic. {fleet-server} is scalable, highly available with traffic ingress,
and load balanced across multiple instances to satisfy the scale requirements.

For step-by-step instructions, go to <<add-fleet-server-cloud>>.

image::images/fleet-server-cloud-deployment.png[{fleet-server} Cloud deployment model]

// text description?

[discrete]
[[deployed-on-prem]]
== Deploy on-premises and self-managed

// What is it...
Alternatively, you can deploy {fleet-server} on-premises and managed it yourself.
In this deployment model, you are responsible for {fleet-server} deployment
and lifecycle management.

// Benefits
This approach might be right for you if you would like to limit the control plane traffic
out of your data center or have requirements for fully air-gapped operations.
For example, you might take this approach if you need to satisfy data governance requirements
or you want agents to only have access to a private segmented network.

// Limitations
This approach might not be right for you if you don't want to manage the life-cycle
of your Elastic environment and instead would like that to be handled by Elastic.

// How to
When using this approach, it's recommended that you provision multiple instances of
the {fleet-server} and use a load balancer to better scale the deployment.
You also have the option to use the organization's own certificate to establish a
secure connection from {fleet-server} to {es}.

For step-by-step instructions, go to <<add-fleet-server-on-prem>>.

image::images/fleet-server-on-prem-deployment.png[{fleet-server} on-premises deployment model]

// text description?

[discrete]
[[fleet-server-on-prem-es-cloud]]
== Deploy {fleet-server} on-premises and {es} on Cloud

// What is it...
Another approach is to aggregate the control and data plane traffic at the local
site and have your {es} cluster managed in {ecloud}.

// Benefits
This approach might be right for you if you would like to limit the control plane traffic
out of your data center. For example, you might take this approach if you are a
managed service provider or a larger enterprise that segregates its networks.

// Limitations
This approach might not be right for you if you don't want to manage the life-cycle
of an extra compute resource in your environment for {fleet-server} to reside on.

// How to
To accommodate these use cases you may deploy a cluster of {fleet-server}s on-premises and
connect them back to the {ecloud} with access to {es} and {kib}.

For step-by-step instructions, go to <<add-fleet-server-mixed>>.

image::images/fleet-server-on-prem-es-cloud.png[{fleet-server} on-premise and {es} on Cloud deployment model]

// text description?

// [discrete]
// [[fleet-server-HA-operations]]
// == {fleet-server} High availability operations

// {fleet-server} is stateless. Connections to the {fleet-server} therefore can be
// load balanced as long as the {fleet-server} has capacity to accept more
// connections. Load balancing is done on a round-robin basis.

// In the {ecloud} deployment model, multiple {fleet-server}s are automatically
// provisioned to satisfy the instance size chosen (instance sizes are modified to
// satisfy the scale requirement). In addition, if you choose multiple
// availability zones to address your fault-tolerance requirements, those
// instances are also utilized to balance the load.

// In an on-premises deployment, high-availability, fault-tolerance, and lifecycle
// management of the {fleet-server} are the responsibility of the administrator.


// [discrete]
// [[fleet-server-default-ports]]
// == Use default port assignments

// When {es} or {fleet-server} are deployed on-premises, communication between certain
// components will take place over well defined, pre-allocated ports.
// In most cases the operators may need to allow access to these ports.

// [options,header]
// |====
// | Component Communication | Default Port
// | Elastic Agent → {fleet-server} | 8220
// | Elastic Agent → {es} | 9200
// | Elastic Agent → Logstash | 5044
// | Elastic Agent → {fleet} | 5601
// | {fleet-server} → {fleet} | 5601
// | {fleet-server} → {es} | 9200
// |====
