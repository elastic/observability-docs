[[add-a-fleet-server]]
= Add a {fleet-server}

To use {fleet} for central management, a <<fleet-server,{fleet-server}>> must
be running and accessible to your hosts. There are a few approaches you can take
when deploying {fleet-server}:

* <<deployed-in-cloud>> as part of the hosted {ess}. Elastic manages both {fleet-server} and {es}.
* <<deployed-on-prem>> to work with {es} running on-premises. You self-manage both {fleet-server} and {es}.
* <<fleet-server-on-prem-es-cloud>>. You manage {fleet-server} and Elastic manages {es}.

Read more about each to choose the best approach for your situation.

[discrete]
[[deployed-in-cloud]]
== Provision {fleet-server} on {ecloud}

{fleet-server} can be provisioned and hosted on {ecloud}. In this case,
when the deployment is created, a highly available set of {fleet-server}s
is automatically deployed.

This approach might be right for you if you want to reduce on-prem compute resources
and you'd like Elastic to take care of provisioning and life cycle management of
your deployment.

With this approach, multiple {fleet-server}s are automatically provisioned to satisfy
the chosen instance size (instance sizes are modified to satisfy the scale requirement).
You can also choose the resources allocated to each {fleet-server} and whether you want
each {fleet-server} to be deployed in multiple availability zones.
If you choose multiple availability zones to address your fault-tolerance
requirements, those instances are also utilized to balance the load.

This approach might _not_ be right for you if you have restrictions on connectivity
to the internet.

For step-by-step instructions, go to <<add-fleet-server-cloud>>.

image::images/fleet-server-cloud-deployment.png[{fleet-server} Cloud deployment model]

[discrete]
[[deployed-on-prem]]
== Deploy {fleet-server} on-premises

Alternatively, you can deploy {fleet-server} on-premises and manage it yourself.
In this deployment model, you are responsible for high-availability, fault-tolerance,
and lifecycle management of {fleet-server}.

This approach might be right for you if you would like to limit the control plane traffic
out of your data center or have requirements for fully air-gapped operations.
For example, you might take this approach if you need to satisfy data governance requirements
or you want agents to only have access to a private segmented network.

This approach might _not_ be right for you if you don't want to manage the life cycle
of your Elastic environment and instead would like that to be handled by Elastic.

When using this approach, it's recommended that you provision multiple instances of
the {fleet-server} and use a load balancer to better scale the deployment.
You also have the option to use your organization's certificate to establish a
secure connection from {fleet-server} to {es}.

For step-by-step instructions, go to <<add-fleet-server-on-prem>>.

image::images/fleet-server-on-prem-deployment.png[{fleet-server} on-premises deployment model]

[discrete]
[[fleet-server-on-prem-es-cloud]]
== Deploy {fleet-server} on-premises to work with a hosted {ess}

Another approach is to deploy a cluster of {fleet-server}s on-premises and
connect them back to {ecloud} with access to {es} and {kib}.
In this deployment model, you are responsible for high-availability, fault-tolerance,
and lifecycle management of {fleet-server}.

This approach might be right for you if you would like to limit the control plane traffic
out of your data center. For example, you might take this approach if you are a
managed service provider or a larger enterprise that segregates its networks.

This approach might _not_ be right for you if you don't want to manage the life cycle
of an extra compute resource in your environment for {fleet-server} to reside on.

For step-by-step instructions, go to <<add-fleet-server-mixed>>.

image::images/fleet-server-on-prem-es-cloud.png[{fleet-server} on-premise and {es} on Cloud deployment model]
