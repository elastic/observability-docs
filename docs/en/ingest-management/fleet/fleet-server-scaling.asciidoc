[discrete]
[[fleet-server-scalability]]
== {fleet-server} scalability

This section summarizes the resource and {fleet-server} configuration
requirements needed to scale your deployment of {agent}s. To scale
{fleet-server}, you need to modify settings in your deployment and the
{fleet-server} agent policy.

First modify your {fleet} deployment settings in {ecloud}:

. Log in to {ecloud} and go to your deployment.

. Under *Deployments > _deployment name_*, click *Edit*.

. Under APM & Fleet:
+
--
* Modify the compute resources available to the server to accommodate a higher
scale of {agent}s
* Modify the availability zones to satisfy fault tolerance requirements

For recommended settings, refer to <<scaling-recommendations>>.

[role="screenshot"]
image::images/fleet-server-hosted-container.png[{fleet-server} hosted agent]
--

Next modify the {fleet-server} configuration by editing the agent policy: 

. In *Fleet*, click *Agent Policies*. Click on the *{ecloud} agent policy* to
edit it.

. Open the *Actions* menu and select *Edit integration*.
+
[role="screenshot"]
image::images/elastic-cloud-agent-policy.png[{ecloud} policy]

. Under {fleet-server}, modify *Max Connections* and other
<<fleet-server-configuration,advanced settings>> as described in
<<scaling-recommendations>>. 
+
[role="screenshot"]
image::images/fleet-server-configuration.png[{fleet-server} configuration]

[discrete]
[[fleet-server-configuration]]
=== Advanced {fleet-server} options

The following advanced settings are available to fine tune your {fleet-server}
deployment.

`cache`::

`num_counters`:::
Size of the hash table. Best practice is to have this set to 10x max
connections.

`max_cost`:::
Total size of the cache.

`server.limits`::
`policy_throttle`:::
How often a new policy is rolled out to the agents.

`checkin_limit.interval`:::
How fast the agents can check in to the {fleet-server}.

`checkin_limit.burst`:::
Burst of check-ins allowed before falling back to the rate defined by
`interval`.

`checkin_limit.max`:::
Maximum number of agents.

`artifact_limit.max`:::
Maximum number of agents that can call the artifact API concurrently. It allows
the user to avoid overloading the {fleet-server} from artifact API calls.

`artifact_limit.interval`:::
How often artifacts are rolled out. Default of 100ms allows 10 artifacts to be
rolled out per second.

`artifact_limit.burst`:::
Number of transactions allowed for a burst, controlling oversubscription on
outbound buffer.

`ack_limit.max`:::
Maximum number of agents that can call the Ack API concurrently. It allows the
user to avoid overloading the {fleet-server} from Ack API calls.

`ack_limit.interval`:::
How often an acknowledgment (ACK) is sent. Default value of 10ms enables 100
ACKs per second to be sent.

`ack_limit.burst`:::
Burst of ACKs to accommodate (default of 20) before falling back to the rate
defined in `interval`.

`enroll_limit.max`:::
Maximum number of agents that can call the Enroll API concurrently. This setting
allows the user to avoid overloading the {fleet-server} from Enrollment API
calls.

`enroll_limit.interval`:::
Interval between processing enrollment request. Enrollment is both CPU and RAM
intensive, so the number of enrollment requests needs to be limited for overall
system health. Default value of 100ms allows 10 enrollments per second.

`enroll_limit.burst`:::
Burst of enrollments to accept before falling back to the rate defined by
`interval`.

[discrete]
[[scaling-recommendations]]
=== Scaling recommendations ({ecloud})

The following tables provide resource requirements and scaling guidelines based
on the number of agents required by your deployment:

* <<resource-requirements-by-number-agents>>
* <<recommend-settings-scaling-agents>>

// TODO: Confirm that these recommendations are current. The values don't match
// the drop-down lists in the latest version of Elastic Cloud. 

[discrete]
[[resource-requirements-by-number-agents]]
==== Resource requirements by number of agents
|===
| Number of Agents | Memory      | vCPU           | {es} Cluster size

| 50               | 512MB       | Up to 2.5 vCPU | 480GB disk \| 16GB RAM \| up to 5 vCPU
| 5,000            | 1GB         | Up to 2.5 vCPU | 960GB disk \| 32GB RAM \| 5 vCPU
| 7,500            | 2GB         | Up to 2.5 vCPU | 1.88TB disk \| 64GB RAM \| 9.8 vCPU
| 10,000           | 4GB         | Up to 2.5 vCPU | 3.75TB disk \| 128GB RAM \| 19.8 vCPU
| 12,500           | 8G          | Up to 2.5 vCPU | 7.5TB disk \| 256GB RAM \| 39.4 vCPU
| 30,000           | 16GB        | 2.5 vCPU       | 7.5TB disk \| 256GB RAM \| 39.4 vCPU
| 50,000           | 32GB        | 2.5 vCPU       | 11.25TB disk \| 384GB RAM \|59.2 vCPU
|===


[discrete]
[[recommend-settings-scaling-agents]]

==== Recommended settings by number of deployed {agent}s

TIP: You might need to scroll to the right to see all the table columns.

|===
|                      | *50*    | *5,000*  | *7,500*  | *10,000* | *12,500*  | *30,000*   | *50,000*
| *Max Connections*    | 100     | 7,000    | 10,000   | 20,000   | 32,000    | 32,000     | 32,000
8+s| Cache settings
| `num_counters`       | 2000    | 20000    | 40000    | 80000     | 160000    | 160000    | 320000
| `max_cost`           | 2097152 | 20971520 | 50971520 | 104857600 | 209715200 | 209715200 | 209715200
8+s| Server limits
| `policy_throttle`    | 200ms   | 50ms     | 10ms     | 5ms       | 5ms       | 2ms       | 5ms
8+| `checkin_limit:`
>| `interval`          | 50ms    | 5ms      | 2ms      | 1ms       | 500us     | 500us     | 500us
>| `burst`             | 25      | 500      | 1000     | 2000      | 4000      | 4000      | 4000
>| `max`               | 100     | 5001     | 7501     | 10001     | 12501     | 15001     | 25001
8+|`artifact_limit:`
>| `interval`          | 100ms   | 5ms      | 2ms      | 1ms       | 500us     | 500us     | 500us
>| `burst`             | 10      | 500      | 1000     | 2000      | 4000      | 4000      | 4000
>| `max`               | 10      | 1000     | 2000     | 4000      | 8000      | 8000      | 8000
8+| `ack_limit:`
>| `interval`          | 10ms    | 4ms      | 2ms      | 1ms       | 500us     | 500us     | 500us
>| `burst`             | 20      | 500      | 1000     | 2000      | 4000      | 4000      | 4000
>| `max`               | 20      | 1000     | 2000     | 4000      | 8000      | 8000      | 8000
8+| `enroll_limit:`
>| `interval`          | 100ms   | 20ms     | 10ms     | 10ms      | 10ms      | 10ms      | 10ms
>| `burst`             | 5       | 50       | 100      | 100       | 100       | 100       | 100
>| `max`               | 10      | 100      | 200      | 200       | 200       | 200       | 200
8+s| Server runtime settings
| `gc_percent`         | 20      | 20       | 20       | 20        | 20        | 20        | 20
|===


[discrete]
[[fleet-server-monitoring]]
== {fleet-server} monitoring

Monitoring {fleet-server} is key since the operation of the {fleet-server} is
paramount to the health of the deployed agents and the services they offer. When
{fleet-server} is not operating correctly, it may lead to delayed check-ins,
status information, and updates for the agents it manages. The monitoring data
will tell you when to add capacity for {fleet-server}, and provide error logs
and information to troubleshoot other issues.

To enable monitoring for {fleet-server}, turn on agent monitoring in the agent
policy. For self-managed clusters, monitoring is on by default when you create a
new agent policy or use the existing Default {fleet-server} agent policy.
However, it is off by default in the {ecloud} agent policy because monitoring
requires additional RAM.

To turn on {fleet-server} monitoring in the agent policy:

. In {fleet}, go to *Agent Policies* and click on the *{ecloud} agent policy*.
+
[role="screenshot"]
image::images/fleet-policy-page.png[Fleet Policy Page]

. Click the *Settings* tab and notice that Agent monitoring is
off by default.

. Under *Agent monitoring*, select *Collect agent logs* and
*Collect agent metrics*.
+
--
[role="screenshot"]
image::images/elastic-cloud-agent-policy-page.png[{ecloud} Policy Page]

The agent will now be able to collect logs and metrics from the {fleet-server}.

NOTE: The {fleet-server} is deployed as yet another agent in the system.
--

. Next, set the *Default namespace*.
+
Setting the default namespace lets you segregate {fleet-server} monitoring data
from other collected data. This makes it easier to search and visualize the
monitoring data. By default the monitoring data is sent to the *default*
namespace.

. To confirm your change, click *Save changes*.

To see the metrics collected for {fleet-server}, go to *Analytics > Discover*.

In the following example, `fleetserver` was configured as the namespace, and
you can see the metrics collected:

[role="screenshot"]
image::images/dashboard-with-namespace-showing.png[Namespace]

[role="screenshot"]
image::images/datastream-namespace.png[Datastream]

In {kib}, go to *Analytics > Dashboard* and search for the predefined dashboard
called *[Elastic Agent] Agent metrics*. Choose this dashboard, and run a query
based on the `fleetserver` namespace.

The following dashboard shows data for the query `data_stream.namespace:
"fleetserver"`. In this example, you can observe CPU and memory usage as a
metric and then resize the {fleet-server}, if necessary.

[role="screenshot"]
image::images/dashboard-datastream.png[Dashboard Datastream]

Note that as an alternative to running the query, you can hide all metrics
except `fleet_server` in the dashboard.

